{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (1000, 3, 32, 32)\n",
      "X_train:  (49000, 3, 32, 32)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "y_train:  (49000,)\n",
      "y_test:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from Solver import Solver\n",
    "from data_utils.data import get_CIFAR10_data\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape\n",
    "from classifiers.cnn import ThreeLayerConvNet\n",
    "num_train = 1000\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9fa5b75fdfb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'o'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'solver' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "from random import randrange\n",
    "from classifiers import cnn_huge as cnn\n",
    "\n",
    "\n",
    "num_train = 500\n",
    "\n",
    "sample = randrange(0,(49000-1)-num_train)\n",
    "\n",
    "small_data = {\n",
    "  'X_train': data['X_train'],#[:num_train],\n",
    "  'y_train': data['y_train'],#[:num_train],\n",
    "  'X_val': data['X_val'],#[:num_train],\n",
    "  'y_val': data['y_val'],#[:num_train],\n",
    "}\n",
    "\n",
    "small_data['X_train'] -= small_data['X_train'].mean(axis=0)\n",
    "small_data['X_val'] -= small_data['X_val'].mean(axis=0)\n",
    "\n",
    "#print small_data['X_train']\n",
    "res = cnn.ResNet(weight_scale=5.4e-02,reg=0.00)\n",
    "solver = Solver(res, small_data,\n",
    "                    update_rule='adam',\n",
    "                    optim_config={\n",
    "                      'learning_rate': 1e-3,\n",
    "                      'stride': 1\n",
    "                    },\n",
    "                    verbose=True,\n",
    "                    num_epochs=10, batch_size=64,\n",
    "                    print_every=1)\n",
    "\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running weight scale 1 / 20\n",
      "(Iteration 1 / 100) loss: 2.302406\n",
      "(Epoch 0 / 10) train acc: 0.112000; val_acc: 0.114000\n",
      "(Iteration 2 / 100) loss: 2.342012\n",
      "(Iteration 3 / 100) loss: 2.352511\n",
      "(Iteration 4 / 100) loss: 2.318581\n",
      "(Iteration 5 / 100) loss: 2.294104\n",
      "(Iteration 6 / 100) loss: 2.258667\n",
      "(Iteration 7 / 100) loss: 2.422350\n",
      "(Iteration 8 / 100) loss: 2.320573\n",
      "(Iteration 9 / 100) loss: 2.312049\n",
      "(Iteration 10 / 100) loss: 2.212682\n",
      "(Epoch 1 / 10) train acc: 0.178000; val_acc: 0.106000\n",
      "(Iteration 11 / 100) loss: 2.276698\n",
      "(Iteration 12 / 100) loss: 2.337473\n",
      "(Iteration 13 / 100) loss: 2.259002\n",
      "(Iteration 14 / 100) loss: 2.280259\n",
      "(Iteration 15 / 100) loss: 2.187314\n",
      "(Iteration 16 / 100) loss: 2.192568\n",
      "(Iteration 17 / 100) loss: 2.248953\n",
      "(Iteration 18 / 100) loss: 2.164723\n",
      "(Iteration 19 / 100) loss: 2.234350\n",
      "(Iteration 20 / 100) loss: 2.209394\n",
      "(Epoch 2 / 10) train acc: 0.210000; val_acc: 0.132000\n",
      "(Iteration 21 / 100) loss: 2.135870\n",
      "(Iteration 22 / 100) loss: 2.193397\n",
      "(Iteration 23 / 100) loss: 2.208339\n",
      "(Iteration 24 / 100) loss: 2.126743\n",
      "(Iteration 25 / 100) loss: 2.241822\n",
      "(Iteration 26 / 100) loss: 2.152032\n",
      "(Iteration 27 / 100) loss: 2.100468\n",
      "(Iteration 28 / 100) loss: 2.245567\n",
      "(Iteration 29 / 100) loss: 2.114111\n",
      "(Iteration 30 / 100) loss: 2.174968\n",
      "(Epoch 3 / 10) train acc: 0.280000; val_acc: 0.206000\n",
      "(Iteration 31 / 100) loss: 2.292688\n",
      "(Iteration 32 / 100) loss: 2.035600\n",
      "(Iteration 33 / 100) loss: 2.032514\n",
      "(Iteration 34 / 100) loss: 2.217926\n",
      "(Iteration 35 / 100) loss: 2.167235\n",
      "(Iteration 36 / 100) loss: 2.197254\n",
      "(Iteration 37 / 100) loss: 2.057014\n",
      "(Iteration 38 / 100) loss: 2.095590\n",
      "(Iteration 39 / 100) loss: 2.108467\n",
      "(Iteration 40 / 100) loss: 2.146962\n",
      "(Epoch 4 / 10) train acc: 0.238000; val_acc: 0.148000\n",
      "(Iteration 41 / 100) loss: 2.215891\n",
      "(Iteration 42 / 100) loss: 2.281942\n",
      "(Iteration 43 / 100) loss: 2.059503\n",
      "(Iteration 44 / 100) loss: 2.185921\n",
      "(Iteration 45 / 100) loss: 2.119867\n",
      "(Iteration 46 / 100) loss: 2.005226\n",
      "(Iteration 47 / 100) loss: 2.181416\n",
      "(Iteration 48 / 100) loss: 1.979705\n",
      "(Iteration 49 / 100) loss: 1.988343\n",
      "(Iteration 50 / 100) loss: 2.213540\n",
      "(Epoch 5 / 10) train acc: 0.260000; val_acc: 0.198000\n",
      "(Iteration 51 / 100) loss: 2.140075\n",
      "(Iteration 52 / 100) loss: 2.119268\n",
      "(Iteration 53 / 100) loss: 1.981544\n",
      "(Iteration 54 / 100) loss: 2.032757\n",
      "(Iteration 55 / 100) loss: 2.045586\n",
      "(Iteration 56 / 100) loss: 1.852654\n",
      "(Iteration 57 / 100) loss: 2.108955\n",
      "(Iteration 58 / 100) loss: 2.167686\n",
      "(Iteration 59 / 100) loss: 1.952451\n",
      "(Iteration 60 / 100) loss: 2.107370\n",
      "(Epoch 6 / 10) train acc: 0.356000; val_acc: 0.178000\n",
      "(Iteration 61 / 100) loss: 2.102729\n",
      "(Iteration 62 / 100) loss: 1.998999\n",
      "(Iteration 63 / 100) loss: 1.992863\n",
      "(Iteration 64 / 100) loss: 1.905127\n",
      "(Iteration 65 / 100) loss: 2.087120\n",
      "(Iteration 66 / 100) loss: 2.025267\n",
      "(Iteration 67 / 100) loss: 1.860664\n",
      "(Iteration 68 / 100) loss: 1.876098\n",
      "(Iteration 69 / 100) loss: 1.870937\n",
      "(Iteration 70 / 100) loss: 1.934706\n",
      "(Epoch 7 / 10) train acc: 0.348000; val_acc: 0.196000\n",
      "(Iteration 71 / 100) loss: 1.835529\n",
      "(Iteration 72 / 100) loss: 2.009644\n",
      "(Iteration 73 / 100) loss: 2.000957\n",
      "(Iteration 74 / 100) loss: 1.968429\n",
      "(Iteration 75 / 100) loss: 1.762363\n",
      "(Iteration 76 / 100) loss: 2.038252\n",
      "(Iteration 77 / 100) loss: 1.958357\n",
      "(Iteration 78 / 100) loss: 1.941805\n",
      "(Iteration 79 / 100) loss: 1.843829\n",
      "(Iteration 80 / 100) loss: 1.913037\n",
      "(Epoch 8 / 10) train acc: 0.336000; val_acc: 0.182000\n",
      "(Iteration 81 / 100) loss: 1.981899\n",
      "(Iteration 82 / 100) loss: 1.974448\n",
      "(Iteration 83 / 100) loss: 1.931104\n",
      "(Iteration 84 / 100) loss: 1.996670\n",
      "(Iteration 85 / 100) loss: 1.918283\n",
      "(Iteration 86 / 100) loss: 1.863464\n",
      "(Iteration 87 / 100) loss: 1.992101\n",
      "(Iteration 88 / 100) loss: 2.104012\n",
      "(Iteration 89 / 100) loss: 1.936551\n",
      "(Iteration 90 / 100) loss: 1.837424\n",
      "(Epoch 9 / 10) train acc: 0.332000; val_acc: 0.184000\n",
      "(Iteration 91 / 100) loss: 1.868141\n",
      "(Iteration 92 / 100) loss: 2.013912\n",
      "(Iteration 93 / 100) loss: 1.993862\n",
      "(Iteration 94 / 100) loss: 2.184931\n",
      "(Iteration 95 / 100) loss: 2.061051\n",
      "(Iteration 96 / 100) loss: 1.838432\n",
      "(Iteration 97 / 100) loss: 1.753651\n",
      "(Iteration 98 / 100) loss: 1.893781\n",
      "(Iteration 99 / 100) loss: 1.947340\n",
      "(Iteration 100 / 100) loss: 1.916873\n",
      "(Epoch 10 / 10) train acc: 0.364000; val_acc: 0.212000\n",
      "Running weight scale 2 / 20\n",
      "(Iteration 1 / 100) loss: 2.306597\n",
      "(Epoch 0 / 10) train acc: 0.112000; val_acc: 0.114000\n",
      "(Iteration 2 / 100) loss: 2.380999\n",
      "(Iteration 3 / 100) loss: 2.317597\n",
      "(Iteration 4 / 100) loss: 2.322272\n",
      "(Iteration 5 / 100) loss: 2.228040\n",
      "(Iteration 6 / 100) loss: 2.310986\n",
      "(Iteration 7 / 100) loss: 2.334725\n",
      "(Iteration 8 / 100) loss: 2.299235\n",
      "(Iteration 9 / 100) loss: 2.246021\n",
      "(Iteration 10 / 100) loss: 2.315869\n",
      "(Epoch 1 / 10) train acc: 0.162000; val_acc: 0.132000\n",
      "(Iteration 11 / 100) loss: 2.177621\n",
      "(Iteration 12 / 100) loss: 2.138344\n",
      "(Iteration 13 / 100) loss: 2.178601\n",
      "(Iteration 14 / 100) loss: 2.097713\n",
      "(Iteration 15 / 100) loss: 2.142066\n",
      "(Iteration 16 / 100) loss: 2.135075\n",
      "(Iteration 17 / 100) loss: 2.064411\n",
      "(Iteration 18 / 100) loss: 2.040378\n",
      "(Iteration 19 / 100) loss: 2.200539\n",
      "(Iteration 20 / 100) loss: 2.227050\n",
      "(Epoch 2 / 10) train acc: 0.210000; val_acc: 0.190000\n",
      "(Iteration 21 / 100) loss: 2.142804\n",
      "(Iteration 22 / 100) loss: 2.053969\n",
      "(Iteration 23 / 100) loss: 2.211372\n",
      "(Iteration 24 / 100) loss: 1.995280\n",
      "(Iteration 25 / 100) loss: 2.031809\n",
      "(Iteration 26 / 100) loss: 1.997230\n",
      "(Iteration 27 / 100) loss: 1.855537\n",
      "(Iteration 28 / 100) loss: 2.217211\n",
      "(Iteration 29 / 100) loss: 2.128995\n",
      "(Iteration 30 / 100) loss: 1.946642\n",
      "(Epoch 3 / 10) train acc: 0.298000; val_acc: 0.248000\n",
      "(Iteration 31 / 100) loss: 1.873674\n",
      "(Iteration 32 / 100) loss: 2.105032\n",
      "(Iteration 33 / 100) loss: 2.015341\n",
      "(Iteration 34 / 100) loss: 1.836284\n",
      "(Iteration 35 / 100) loss: 2.210588\n",
      "(Iteration 36 / 100) loss: 1.925539\n",
      "(Iteration 37 / 100) loss: 1.898922\n",
      "(Iteration 38 / 100) loss: 2.123166\n",
      "(Iteration 39 / 100) loss: 1.928003\n",
      "(Iteration 40 / 100) loss: 1.961787\n",
      "(Epoch 4 / 10) train acc: 0.326000; val_acc: 0.210000\n",
      "(Iteration 41 / 100) loss: 1.882684\n",
      "(Iteration 42 / 100) loss: 1.864392\n",
      "(Iteration 43 / 100) loss: 1.890746\n",
      "(Iteration 44 / 100) loss: 1.771687\n",
      "(Iteration 45 / 100) loss: 2.241897\n",
      "(Iteration 46 / 100) loss: 2.098130\n",
      "(Iteration 47 / 100) loss: 2.078106\n",
      "(Iteration 48 / 100) loss: 1.960324\n",
      "(Iteration 49 / 100) loss: 1.726872\n",
      "(Iteration 50 / 100) loss: 1.945559\n",
      "(Epoch 5 / 10) train acc: 0.326000; val_acc: 0.222000\n",
      "(Iteration 51 / 100) loss: 2.062000\n",
      "(Iteration 52 / 100) loss: 1.962887\n",
      "(Iteration 53 / 100) loss: 1.970427\n",
      "(Iteration 54 / 100) loss: 1.899321\n",
      "(Iteration 55 / 100) loss: 1.897024\n",
      "(Iteration 56 / 100) loss: 2.025217\n",
      "(Iteration 57 / 100) loss: 1.869591\n",
      "(Iteration 58 / 100) loss: 1.748550\n",
      "(Iteration 59 / 100) loss: 1.977044\n",
      "(Iteration 60 / 100) loss: 1.829442\n",
      "(Epoch 6 / 10) train acc: 0.344000; val_acc: 0.204000\n",
      "(Iteration 61 / 100) loss: 1.874102\n",
      "(Iteration 62 / 100) loss: 1.917426\n",
      "(Iteration 63 / 100) loss: 1.900622\n",
      "(Iteration 64 / 100) loss: 1.829268\n",
      "(Iteration 65 / 100) loss: 1.877190\n",
      "(Iteration 66 / 100) loss: 1.793604\n",
      "(Iteration 67 / 100) loss: 1.867710\n",
      "(Iteration 68 / 100) loss: 1.669190\n",
      "(Iteration 69 / 100) loss: 1.856991\n",
      "(Iteration 70 / 100) loss: 1.947600\n",
      "(Epoch 7 / 10) train acc: 0.372000; val_acc: 0.238000\n",
      "(Iteration 71 / 100) loss: 1.783571\n",
      "(Iteration 72 / 100) loss: 1.750227\n",
      "(Iteration 73 / 100) loss: 1.956085\n",
      "(Iteration 74 / 100) loss: 1.902516\n",
      "(Iteration 75 / 100) loss: 1.925639\n",
      "(Iteration 76 / 100) loss: 1.797879\n",
      "(Iteration 77 / 100) loss: 1.992032\n",
      "(Iteration 78 / 100) loss: 1.714337\n",
      "(Iteration 79 / 100) loss: 1.891471\n",
      "(Iteration 80 / 100) loss: 1.861408\n",
      "(Epoch 8 / 10) train acc: 0.376000; val_acc: 0.242000\n",
      "(Iteration 81 / 100) loss: 1.876717\n",
      "(Iteration 82 / 100) loss: 1.724911\n",
      "(Iteration 83 / 100) loss: 1.852665\n",
      "(Iteration 84 / 100) loss: 1.687230\n",
      "(Iteration 85 / 100) loss: 1.880458\n",
      "(Iteration 86 / 100) loss: 1.869018\n",
      "(Iteration 87 / 100) loss: 1.779777\n",
      "(Iteration 88 / 100) loss: 1.687819\n",
      "(Iteration 89 / 100) loss: 1.719980\n",
      "(Iteration 90 / 100) loss: 1.818277\n",
      "(Epoch 9 / 10) train acc: 0.388000; val_acc: 0.234000\n",
      "(Iteration 91 / 100) loss: 1.965097\n",
      "(Iteration 92 / 100) loss: 1.796786\n",
      "(Iteration 93 / 100) loss: 1.818161\n",
      "(Iteration 94 / 100) loss: 1.915275\n",
      "(Iteration 95 / 100) loss: 1.751459\n",
      "(Iteration 96 / 100) loss: 1.885020\n",
      "(Iteration 97 / 100) loss: 1.864004\n",
      "(Iteration 98 / 100) loss: 1.874742\n",
      "(Iteration 99 / 100) loss: 1.830078\n",
      "(Iteration 100 / 100) loss: 1.814584\n",
      "(Epoch 10 / 10) train acc: 0.404000; val_acc: 0.246000\n",
      "Running weight scale 3 / 20\n",
      "(Iteration 1 / 100) loss: 2.309218\n",
      "(Epoch 0 / 10) train acc: 0.108000; val_acc: 0.110000\n",
      "(Iteration 2 / 100) loss: 2.301051\n",
      "(Iteration 3 / 100) loss: 2.388427\n",
      "(Iteration 4 / 100) loss: 2.347620\n",
      "(Iteration 5 / 100) loss: 2.448392\n",
      "(Iteration 6 / 100) loss: 2.305407\n",
      "(Iteration 7 / 100) loss: 2.282474\n",
      "(Iteration 8 / 100) loss: 2.320112\n",
      "(Iteration 9 / 100) loss: 2.377301\n",
      "(Iteration 10 / 100) loss: 2.381695\n",
      "(Epoch 1 / 10) train acc: 0.168000; val_acc: 0.126000\n",
      "(Iteration 11 / 100) loss: 2.347356\n",
      "(Iteration 12 / 100) loss: 2.283112\n",
      "(Iteration 13 / 100) loss: 2.247245\n",
      "(Iteration 14 / 100) loss: 2.215630\n",
      "(Iteration 15 / 100) loss: 2.247020\n",
      "(Iteration 16 / 100) loss: 2.251389\n",
      "(Iteration 17 / 100) loss: 2.141961\n",
      "(Iteration 18 / 100) loss: 2.187455\n",
      "(Iteration 19 / 100) loss: 2.168492\n",
      "(Iteration 20 / 100) loss: 2.265776\n",
      "(Epoch 2 / 10) train acc: 0.252000; val_acc: 0.184000\n",
      "(Iteration 21 / 100) loss: 2.146265\n",
      "(Iteration 22 / 100) loss: 2.198891\n",
      "(Iteration 23 / 100) loss: 2.181046\n",
      "(Iteration 24 / 100) loss: 2.110608\n",
      "(Iteration 25 / 100) loss: 2.157777\n",
      "(Iteration 26 / 100) loss: 2.089895\n",
      "(Iteration 27 / 100) loss: 2.273751\n",
      "(Iteration 28 / 100) loss: 2.301457\n",
      "(Iteration 29 / 100) loss: 2.148255\n",
      "(Iteration 30 / 100) loss: 2.012695\n",
      "(Epoch 3 / 10) train acc: 0.264000; val_acc: 0.172000\n",
      "(Iteration 31 / 100) loss: 2.120903\n",
      "(Iteration 32 / 100) loss: 2.164945\n",
      "(Iteration 33 / 100) loss: 2.166790\n",
      "(Iteration 34 / 100) loss: 1.928683\n",
      "(Iteration 35 / 100) loss: 2.102199\n",
      "(Iteration 36 / 100) loss: 1.923386\n",
      "(Iteration 37 / 100) loss: 2.097424\n",
      "(Iteration 38 / 100) loss: 2.177480\n",
      "(Iteration 39 / 100) loss: 2.113739\n",
      "(Iteration 40 / 100) loss: 2.078049\n",
      "(Epoch 4 / 10) train acc: 0.272000; val_acc: 0.178000\n",
      "(Iteration 41 / 100) loss: 2.080167\n",
      "(Iteration 42 / 100) loss: 1.997263\n",
      "(Iteration 43 / 100) loss: 2.030803\n",
      "(Iteration 44 / 100) loss: 1.966125\n",
      "(Iteration 45 / 100) loss: 2.033226\n",
      "(Iteration 46 / 100) loss: 1.981888\n",
      "(Iteration 47 / 100) loss: 2.131496\n",
      "(Iteration 48 / 100) loss: 1.959619\n",
      "(Iteration 49 / 100) loss: 2.063855\n",
      "(Iteration 50 / 100) loss: 2.106882\n",
      "(Epoch 5 / 10) train acc: 0.324000; val_acc: 0.196000\n",
      "(Iteration 51 / 100) loss: 1.906445\n",
      "(Iteration 52 / 100) loss: 1.971193\n",
      "(Iteration 53 / 100) loss: 2.074797\n",
      "(Iteration 54 / 100) loss: 1.933551\n",
      "(Iteration 55 / 100) loss: 2.053137\n",
      "(Iteration 56 / 100) loss: 1.936244\n",
      "(Iteration 57 / 100) loss: 2.081909\n",
      "(Iteration 58 / 100) loss: 1.911488\n",
      "(Iteration 59 / 100) loss: 1.928247\n",
      "(Iteration 60 / 100) loss: 1.910233\n",
      "(Epoch 6 / 10) train acc: 0.344000; val_acc: 0.216000\n",
      "(Iteration 61 / 100) loss: 1.998486\n",
      "(Iteration 62 / 100) loss: 1.929563\n",
      "(Iteration 63 / 100) loss: 1.801567\n",
      "(Iteration 64 / 100) loss: 1.858456\n",
      "(Iteration 65 / 100) loss: 1.938768\n",
      "(Iteration 66 / 100) loss: 1.954460\n",
      "(Iteration 67 / 100) loss: 1.814239\n",
      "(Iteration 68 / 100) loss: 1.991203\n",
      "(Iteration 69 / 100) loss: 1.839763\n",
      "(Iteration 70 / 100) loss: 1.840849\n",
      "(Epoch 7 / 10) train acc: 0.354000; val_acc: 0.224000\n",
      "(Iteration 71 / 100) loss: 1.807012\n",
      "(Iteration 72 / 100) loss: 1.903931\n",
      "(Iteration 73 / 100) loss: 1.790045\n",
      "(Iteration 74 / 100) loss: 1.744040\n",
      "(Iteration 75 / 100) loss: 1.970969\n",
      "(Iteration 76 / 100) loss: 1.786404\n",
      "(Iteration 77 / 100) loss: 2.066452\n",
      "(Iteration 78 / 100) loss: 2.015352\n",
      "(Iteration 79 / 100) loss: 1.894377\n",
      "(Iteration 80 / 100) loss: 1.921517\n",
      "(Epoch 8 / 10) train acc: 0.364000; val_acc: 0.218000\n",
      "(Iteration 81 / 100) loss: 1.825991\n",
      "(Iteration 82 / 100) loss: 1.745899\n",
      "(Iteration 83 / 100) loss: 2.084191\n",
      "(Iteration 84 / 100) loss: 1.990485\n",
      "(Iteration 85 / 100) loss: 1.855002\n",
      "(Iteration 86 / 100) loss: 1.814590\n",
      "(Iteration 87 / 100) loss: 1.848286\n",
      "(Iteration 88 / 100) loss: 1.814011\n",
      "(Iteration 89 / 100) loss: 1.826471\n",
      "(Iteration 90 / 100) loss: 1.637365\n",
      "(Epoch 9 / 10) train acc: 0.378000; val_acc: 0.220000\n",
      "(Iteration 91 / 100) loss: 1.788336\n",
      "(Iteration 92 / 100) loss: 2.090442\n",
      "(Iteration 93 / 100) loss: 1.892286\n",
      "(Iteration 94 / 100) loss: 1.817613\n",
      "(Iteration 95 / 100) loss: 1.893310\n",
      "(Iteration 96 / 100) loss: 2.034922\n",
      "(Iteration 97 / 100) loss: 1.761767\n",
      "(Iteration 98 / 100) loss: 1.918209\n",
      "(Iteration 99 / 100) loss: 1.977219\n",
      "(Iteration 100 / 100) loss: 1.885278\n",
      "(Epoch 10 / 10) train acc: 0.412000; val_acc: 0.248000\n",
      "Running weight scale 4 / 20\n",
      "(Iteration 1 / 100) loss: 2.319352\n",
      "(Epoch 0 / 10) train acc: 0.134000; val_acc: 0.124000\n",
      "(Iteration 2 / 100) loss: 2.371436\n",
      "(Iteration 3 / 100) loss: 2.494697\n",
      "(Iteration 4 / 100) loss: 2.334413\n",
      "(Iteration 5 / 100) loss: 2.302065\n",
      "(Iteration 6 / 100) loss: 2.254862\n",
      "(Iteration 7 / 100) loss: 2.360698\n",
      "(Iteration 8 / 100) loss: 2.330757\n",
      "(Iteration 9 / 100) loss: 2.305174\n",
      "(Iteration 10 / 100) loss: 2.274425\n",
      "(Epoch 1 / 10) train acc: 0.146000; val_acc: 0.128000\n",
      "(Iteration 11 / 100) loss: 2.263263\n",
      "(Iteration 12 / 100) loss: 2.268625\n",
      "(Iteration 13 / 100) loss: 2.301866\n",
      "(Iteration 14 / 100) loss: 2.287943\n",
      "(Iteration 15 / 100) loss: 2.255194\n",
      "(Iteration 16 / 100) loss: 2.169186\n",
      "(Iteration 17 / 100) loss: 2.222624\n",
      "(Iteration 18 / 100) loss: 2.205111\n",
      "(Iteration 19 / 100) loss: 2.319807\n",
      "(Iteration 20 / 100) loss: 2.262934\n",
      "(Epoch 2 / 10) train acc: 0.234000; val_acc: 0.176000\n",
      "(Iteration 21 / 100) loss: 2.168868\n",
      "(Iteration 22 / 100) loss: 2.242749\n",
      "(Iteration 23 / 100) loss: 2.212845\n",
      "(Iteration 24 / 100) loss: 2.091552\n",
      "(Iteration 25 / 100) loss: 2.168724\n",
      "(Iteration 26 / 100) loss: 2.107245\n",
      "(Iteration 27 / 100) loss: 2.160444\n",
      "(Iteration 28 / 100) loss: 2.159674\n",
      "(Iteration 29 / 100) loss: 2.168890\n",
      "(Iteration 30 / 100) loss: 2.158663\n",
      "(Epoch 3 / 10) train acc: 0.248000; val_acc: 0.170000\n",
      "(Iteration 31 / 100) loss: 2.012057\n",
      "(Iteration 32 / 100) loss: 2.203530\n",
      "(Iteration 33 / 100) loss: 2.135937\n",
      "(Iteration 34 / 100) loss: 2.118618\n",
      "(Iteration 35 / 100) loss: 2.078416\n",
      "(Iteration 36 / 100) loss: 2.129390\n",
      "(Iteration 37 / 100) loss: 1.932764\n",
      "(Iteration 38 / 100) loss: 2.310848\n",
      "(Iteration 39 / 100) loss: 1.944001\n",
      "(Iteration 40 / 100) loss: 2.027142\n",
      "(Epoch 4 / 10) train acc: 0.302000; val_acc: 0.212000\n",
      "(Iteration 41 / 100) loss: 2.032196\n",
      "(Iteration 42 / 100) loss: 2.059194\n",
      "(Iteration 43 / 100) loss: 2.048223\n",
      "(Iteration 44 / 100) loss: 2.272035\n",
      "(Iteration 45 / 100) loss: 2.096037\n",
      "(Iteration 46 / 100) loss: 2.059555\n",
      "(Iteration 47 / 100) loss: 2.078490\n",
      "(Iteration 48 / 100) loss: 2.008164\n",
      "(Iteration 49 / 100) loss: 2.133388\n",
      "(Iteration 50 / 100) loss: 1.991481\n",
      "(Epoch 5 / 10) train acc: 0.318000; val_acc: 0.176000\n",
      "(Iteration 51 / 100) loss: 2.050145\n",
      "(Iteration 52 / 100) loss: 1.963412\n",
      "(Iteration 53 / 100) loss: 2.072100\n",
      "(Iteration 54 / 100) loss: 2.006926\n",
      "(Iteration 55 / 100) loss: 1.941147\n",
      "(Iteration 56 / 100) loss: 2.080351\n",
      "(Iteration 57 / 100) loss: 1.971232\n",
      "(Iteration 58 / 100) loss: 2.019258\n",
      "(Iteration 59 / 100) loss: 2.062829\n",
      "(Iteration 60 / 100) loss: 1.870554\n",
      "(Epoch 6 / 10) train acc: 0.324000; val_acc: 0.210000\n",
      "(Iteration 61 / 100) loss: 1.976068\n",
      "(Iteration 62 / 100) loss: 1.886462\n",
      "(Iteration 63 / 100) loss: 1.870022\n",
      "(Iteration 64 / 100) loss: 2.055740\n",
      "(Iteration 65 / 100) loss: 1.992661\n",
      "(Iteration 66 / 100) loss: 1.872945\n",
      "(Iteration 67 / 100) loss: 2.174807\n",
      "(Iteration 68 / 100) loss: 2.077379\n",
      "(Iteration 69 / 100) loss: 1.996423\n",
      "(Iteration 70 / 100) loss: 1.915854\n",
      "(Epoch 7 / 10) train acc: 0.338000; val_acc: 0.208000\n",
      "(Iteration 71 / 100) loss: 1.969165\n",
      "(Iteration 72 / 100) loss: 1.896543\n",
      "(Iteration 73 / 100) loss: 2.044726\n",
      "(Iteration 74 / 100) loss: 1.867356\n",
      "(Iteration 75 / 100) loss: 1.869879\n",
      "(Iteration 76 / 100) loss: 1.942530\n",
      "(Iteration 77 / 100) loss: 2.013753\n",
      "(Iteration 78 / 100) loss: 2.078193\n",
      "(Iteration 79 / 100) loss: 1.930259\n",
      "(Iteration 80 / 100) loss: 2.074616\n",
      "(Epoch 8 / 10) train acc: 0.350000; val_acc: 0.204000\n",
      "(Iteration 81 / 100) loss: 2.072686\n",
      "(Iteration 82 / 100) loss: 2.082618\n",
      "(Iteration 83 / 100) loss: 2.091241\n",
      "(Iteration 84 / 100) loss: 1.855408\n",
      "(Iteration 85 / 100) loss: 1.955845\n",
      "(Iteration 86 / 100) loss: 2.140445\n",
      "(Iteration 87 / 100) loss: 1.915321\n",
      "(Iteration 88 / 100) loss: 1.980248\n",
      "(Iteration 89 / 100) loss: 1.987208\n",
      "(Iteration 90 / 100) loss: 1.829481\n",
      "(Epoch 9 / 10) train acc: 0.366000; val_acc: 0.228000\n",
      "(Iteration 91 / 100) loss: 1.839930\n",
      "(Iteration 92 / 100) loss: 1.893081\n",
      "(Iteration 93 / 100) loss: 2.001067\n",
      "(Iteration 94 / 100) loss: 1.951151\n",
      "(Iteration 95 / 100) loss: 1.938830\n",
      "(Iteration 96 / 100) loss: 1.965464\n",
      "(Iteration 97 / 100) loss: 1.778754\n",
      "(Iteration 98 / 100) loss: 1.834718\n",
      "(Iteration 99 / 100) loss: 1.761202\n",
      "(Iteration 100 / 100) loss: 1.969002\n",
      "(Epoch 10 / 10) train acc: 0.376000; val_acc: 0.224000\n",
      "Running weight scale 5 / 20\n",
      "(Iteration 1 / 100) loss: 2.331598\n",
      "(Epoch 0 / 10) train acc: 0.136000; val_acc: 0.118000\n",
      "(Iteration 2 / 100) loss: 2.321178\n",
      "(Iteration 3 / 100) loss: 2.542990\n",
      "(Iteration 4 / 100) loss: 2.486351\n",
      "(Iteration 5 / 100) loss: 2.430667\n",
      "(Iteration 6 / 100) loss: 2.382023\n",
      "(Iteration 7 / 100) loss: 2.319890\n",
      "(Iteration 8 / 100) loss: 2.352581\n",
      "(Iteration 9 / 100) loss: 2.312008\n",
      "(Iteration 10 / 100) loss: 2.362692\n",
      "(Epoch 1 / 10) train acc: 0.106000; val_acc: 0.070000\n",
      "(Iteration 11 / 100) loss: 2.319317\n",
      "(Iteration 12 / 100) loss: 2.383094\n",
      "(Iteration 13 / 100) loss: 2.318942\n",
      "(Iteration 14 / 100) loss: 2.300220\n",
      "(Iteration 15 / 100) loss: 2.251729\n",
      "(Iteration 16 / 100) loss: 2.289470\n",
      "(Iteration 17 / 100) loss: 2.240476\n",
      "(Iteration 18 / 100) loss: 2.295514\n",
      "(Iteration 19 / 100) loss: 2.432217\n",
      "(Iteration 20 / 100) loss: 2.333464\n",
      "(Epoch 2 / 10) train acc: 0.158000; val_acc: 0.146000\n",
      "(Iteration 21 / 100) loss: 2.252497\n",
      "(Iteration 22 / 100) loss: 2.177079\n",
      "(Iteration 23 / 100) loss: 2.270148\n",
      "(Iteration 24 / 100) loss: 2.210870\n",
      "(Iteration 25 / 100) loss: 2.178110\n",
      "(Iteration 26 / 100) loss: 2.308416\n",
      "(Iteration 27 / 100) loss: 2.249140\n",
      "(Iteration 28 / 100) loss: 2.191211\n",
      "(Iteration 29 / 100) loss: 2.058945\n",
      "(Iteration 30 / 100) loss: 2.261158\n",
      "(Epoch 3 / 10) train acc: 0.248000; val_acc: 0.204000\n",
      "(Iteration 31 / 100) loss: 2.226838\n",
      "(Iteration 32 / 100) loss: 2.205667\n",
      "(Iteration 33 / 100) loss: 2.176500\n",
      "(Iteration 34 / 100) loss: 2.113894\n",
      "(Iteration 35 / 100) loss: 2.032072\n",
      "(Iteration 36 / 100) loss: 2.067886\n",
      "(Iteration 37 / 100) loss: 2.081147\n",
      "(Iteration 38 / 100) loss: 2.176016\n",
      "(Iteration 39 / 100) loss: 2.069024\n",
      "(Iteration 40 / 100) loss: 2.050664\n",
      "(Epoch 4 / 10) train acc: 0.354000; val_acc: 0.260000\n",
      "(Iteration 41 / 100) loss: 2.112364\n",
      "(Iteration 42 / 100) loss: 2.076275\n",
      "(Iteration 43 / 100) loss: 2.087396\n",
      "(Iteration 44 / 100) loss: 2.008807\n",
      "(Iteration 45 / 100) loss: 2.233109\n",
      "(Iteration 46 / 100) loss: 2.069486\n",
      "(Iteration 47 / 100) loss: 2.092793\n",
      "(Iteration 48 / 100) loss: 1.968191\n",
      "(Iteration 49 / 100) loss: 2.083282\n",
      "(Iteration 50 / 100) loss: 2.066949\n",
      "(Epoch 5 / 10) train acc: 0.292000; val_acc: 0.238000\n",
      "(Iteration 51 / 100) loss: 2.052695\n",
      "(Iteration 52 / 100) loss: 1.982407\n",
      "(Iteration 53 / 100) loss: 2.195023\n",
      "(Iteration 54 / 100) loss: 2.067067\n",
      "(Iteration 55 / 100) loss: 1.918707\n",
      "(Iteration 56 / 100) loss: 1.955412\n",
      "(Iteration 57 / 100) loss: 2.211907\n",
      "(Iteration 58 / 100) loss: 1.931073\n",
      "(Iteration 59 / 100) loss: 2.069671\n",
      "(Iteration 60 / 100) loss: 1.996363\n",
      "(Epoch 6 / 10) train acc: 0.320000; val_acc: 0.250000\n",
      "(Iteration 61 / 100) loss: 2.055030\n",
      "(Iteration 62 / 100) loss: 1.977239\n",
      "(Iteration 63 / 100) loss: 2.024562\n",
      "(Iteration 64 / 100) loss: 2.160078\n",
      "(Iteration 65 / 100) loss: 2.085311\n",
      "(Iteration 66 / 100) loss: 2.095872\n",
      "(Iteration 67 / 100) loss: 1.961230\n",
      "(Iteration 68 / 100) loss: 2.058206\n",
      "(Iteration 69 / 100) loss: 2.019196\n",
      "(Iteration 70 / 100) loss: 1.841730\n",
      "(Epoch 7 / 10) train acc: 0.374000; val_acc: 0.260000\n",
      "(Iteration 71 / 100) loss: 1.817101\n",
      "(Iteration 72 / 100) loss: 2.080856\n",
      "(Iteration 73 / 100) loss: 1.960626\n",
      "(Iteration 74 / 100) loss: 1.906172\n",
      "(Iteration 75 / 100) loss: 1.949269\n",
      "(Iteration 76 / 100) loss: 1.930358\n",
      "(Iteration 77 / 100) loss: 1.923185\n",
      "(Iteration 78 / 100) loss: 1.931550\n",
      "(Iteration 79 / 100) loss: 1.851928\n",
      "(Iteration 80 / 100) loss: 2.057489\n",
      "(Epoch 8 / 10) train acc: 0.354000; val_acc: 0.252000\n",
      "(Iteration 81 / 100) loss: 1.895466\n",
      "(Iteration 82 / 100) loss: 1.874370\n",
      "(Iteration 83 / 100) loss: 2.143608\n",
      "(Iteration 84 / 100) loss: 1.958766\n",
      "(Iteration 85 / 100) loss: 1.886403\n",
      "(Iteration 86 / 100) loss: 2.082690\n",
      "(Iteration 87 / 100) loss: 1.789953\n",
      "(Iteration 88 / 100) loss: 1.824236\n",
      "(Iteration 89 / 100) loss: 2.127208\n",
      "(Iteration 90 / 100) loss: 2.014152\n",
      "(Epoch 9 / 10) train acc: 0.326000; val_acc: 0.248000\n",
      "(Iteration 91 / 100) loss: 1.891176\n",
      "(Iteration 92 / 100) loss: 1.898799\n",
      "(Iteration 93 / 100) loss: 1.832884\n",
      "(Iteration 94 / 100) loss: 1.828217\n",
      "(Iteration 95 / 100) loss: 1.943911\n",
      "(Iteration 96 / 100) loss: 1.840897\n",
      "(Iteration 97 / 100) loss: 1.958195\n",
      "(Iteration 98 / 100) loss: 2.036873\n",
      "(Iteration 99 / 100) loss: 1.884001\n",
      "(Iteration 100 / 100) loss: 1.871084\n",
      "(Epoch 10 / 10) train acc: 0.346000; val_acc: 0.244000\n",
      "Running weight scale 6 / 20\n",
      "(Iteration 1 / 100) loss: 2.428228\n",
      "(Epoch 0 / 10) train acc: 0.112000; val_acc: 0.114000\n",
      "(Iteration 2 / 100) loss: 2.426740\n",
      "(Iteration 3 / 100) loss: 2.427150\n",
      "(Iteration 4 / 100) loss: 2.361409\n",
      "(Iteration 5 / 100) loss: 2.453017\n",
      "(Iteration 6 / 100) loss: 2.410511\n",
      "(Iteration 7 / 100) loss: 2.426609\n",
      "(Iteration 8 / 100) loss: 2.416665\n",
      "(Iteration 9 / 100) loss: 2.382496\n",
      "(Iteration 10 / 100) loss: 2.587135\n",
      "(Epoch 1 / 10) train acc: 0.130000; val_acc: 0.120000\n",
      "(Iteration 11 / 100) loss: 2.490141\n",
      "(Iteration 12 / 100) loss: 2.390811\n",
      "(Iteration 13 / 100) loss: 2.410491\n",
      "(Iteration 14 / 100) loss: 2.389549\n",
      "(Iteration 15 / 100) loss: 2.374375\n",
      "(Iteration 16 / 100) loss: 2.404967\n",
      "(Iteration 17 / 100) loss: 2.407341\n",
      "(Iteration 18 / 100) loss: 2.371354\n",
      "(Iteration 19 / 100) loss: 2.368179\n",
      "(Iteration 20 / 100) loss: 2.421230\n",
      "(Epoch 2 / 10) train acc: 0.172000; val_acc: 0.138000\n",
      "(Iteration 21 / 100) loss: 2.337827\n",
      "(Iteration 22 / 100) loss: 2.405143\n",
      "(Iteration 23 / 100) loss: 2.361410\n",
      "(Iteration 24 / 100) loss: 2.317222\n",
      "(Iteration 25 / 100) loss: 2.350829\n",
      "(Iteration 26 / 100) loss: 2.391125\n",
      "(Iteration 27 / 100) loss: 2.462721\n",
      "(Iteration 28 / 100) loss: 2.387995\n",
      "(Iteration 29 / 100) loss: 2.259371\n",
      "(Iteration 30 / 100) loss: 2.540228\n",
      "(Epoch 3 / 10) train acc: 0.200000; val_acc: 0.160000\n",
      "(Iteration 31 / 100) loss: 2.303908\n",
      "(Iteration 32 / 100) loss: 2.356139\n",
      "(Iteration 33 / 100) loss: 2.325515\n",
      "(Iteration 34 / 100) loss: 2.569048\n",
      "(Iteration 35 / 100) loss: 2.312248\n",
      "(Iteration 36 / 100) loss: 2.447984\n",
      "(Iteration 37 / 100) loss: 2.233332\n",
      "(Iteration 38 / 100) loss: 2.408792\n",
      "(Iteration 39 / 100) loss: 2.422706\n",
      "(Iteration 40 / 100) loss: 2.229029\n",
      "(Epoch 4 / 10) train acc: 0.248000; val_acc: 0.168000\n",
      "(Iteration 41 / 100) loss: 2.234232\n",
      "(Iteration 42 / 100) loss: 2.198302\n",
      "(Iteration 43 / 100) loss: 2.185235\n",
      "(Iteration 44 / 100) loss: 2.276847\n",
      "(Iteration 45 / 100) loss: 2.305677\n",
      "(Iteration 46 / 100) loss: 2.235269\n",
      "(Iteration 47 / 100) loss: 2.160018\n",
      "(Iteration 48 / 100) loss: 2.343969\n",
      "(Iteration 49 / 100) loss: 2.227859\n",
      "(Iteration 50 / 100) loss: 2.191368\n",
      "(Epoch 5 / 10) train acc: 0.256000; val_acc: 0.174000\n",
      "(Iteration 51 / 100) loss: 2.238379\n",
      "(Iteration 52 / 100) loss: 2.233397\n",
      "(Iteration 53 / 100) loss: 2.344754\n",
      "(Iteration 54 / 100) loss: 2.120424\n",
      "(Iteration 55 / 100) loss: 2.189402\n",
      "(Iteration 56 / 100) loss: 2.211147\n",
      "(Iteration 57 / 100) loss: 2.176455\n",
      "(Iteration 58 / 100) loss: 2.220112\n",
      "(Iteration 59 / 100) loss: 2.167258\n",
      "(Iteration 60 / 100) loss: 2.147196\n",
      "(Epoch 6 / 10) train acc: 0.326000; val_acc: 0.172000\n",
      "(Iteration 61 / 100) loss: 2.301545\n",
      "(Iteration 62 / 100) loss: 2.249607\n",
      "(Iteration 63 / 100) loss: 2.151004\n",
      "(Iteration 64 / 100) loss: 1.999942\n",
      "(Iteration 65 / 100) loss: 2.260207\n",
      "(Iteration 66 / 100) loss: 2.180426\n",
      "(Iteration 67 / 100) loss: 2.169582\n",
      "(Iteration 68 / 100) loss: 1.968859\n",
      "(Iteration 69 / 100) loss: 2.142434\n",
      "(Iteration 70 / 100) loss: 2.082986\n",
      "(Epoch 7 / 10) train acc: 0.360000; val_acc: 0.202000\n",
      "(Iteration 71 / 100) loss: 2.167870\n",
      "(Iteration 72 / 100) loss: 2.195091\n",
      "(Iteration 73 / 100) loss: 2.173726\n",
      "(Iteration 74 / 100) loss: 2.086784\n",
      "(Iteration 75 / 100) loss: 2.008556\n",
      "(Iteration 76 / 100) loss: 2.140098\n",
      "(Iteration 77 / 100) loss: 2.016560\n",
      "(Iteration 78 / 100) loss: 2.002698\n",
      "(Iteration 79 / 100) loss: 2.099806\n",
      "(Iteration 80 / 100) loss: 2.011123\n",
      "(Epoch 8 / 10) train acc: 0.388000; val_acc: 0.214000\n",
      "(Iteration 81 / 100) loss: 2.093802\n",
      "(Iteration 82 / 100) loss: 1.999441\n",
      "(Iteration 83 / 100) loss: 2.082507\n",
      "(Iteration 84 / 100) loss: 2.108259\n",
      "(Iteration 85 / 100) loss: 2.154636\n",
      "(Iteration 86 / 100) loss: 1.927636\n",
      "(Iteration 87 / 100) loss: 2.112834\n",
      "(Iteration 88 / 100) loss: 2.127938\n",
      "(Iteration 89 / 100) loss: 1.994802\n",
      "(Iteration 90 / 100) loss: 2.160830\n",
      "(Epoch 9 / 10) train acc: 0.346000; val_acc: 0.214000\n",
      "(Iteration 91 / 100) loss: 2.162528\n",
      "(Iteration 92 / 100) loss: 2.127972\n",
      "(Iteration 93 / 100) loss: 1.946718\n",
      "(Iteration 94 / 100) loss: 1.978174\n",
      "(Iteration 95 / 100) loss: 2.119317\n",
      "(Iteration 96 / 100) loss: 2.099045\n",
      "(Iteration 97 / 100) loss: 2.116132\n",
      "(Iteration 98 / 100) loss: 2.097536\n",
      "(Iteration 99 / 100) loss: 1.947487\n",
      "(Iteration 100 / 100) loss: 2.224887\n",
      "(Epoch 10 / 10) train acc: 0.362000; val_acc: 0.228000\n",
      "Running weight scale 7 / 20\n",
      "(Iteration 1 / 100) loss: 2.616318\n",
      "(Epoch 0 / 10) train acc: 0.100000; val_acc: 0.098000\n",
      "(Iteration 2 / 100) loss: 2.567536\n",
      "(Iteration 3 / 100) loss: 2.508386\n",
      "(Iteration 4 / 100) loss: 2.626968\n",
      "(Iteration 5 / 100) loss: 2.704201\n",
      "(Iteration 6 / 100) loss: 2.575858\n",
      "(Iteration 7 / 100) loss: 2.711736\n",
      "(Iteration 8 / 100) loss: 2.640880\n",
      "(Iteration 9 / 100) loss: 2.655532\n",
      "(Iteration 10 / 100) loss: 2.513505\n",
      "(Epoch 1 / 10) train acc: 0.102000; val_acc: 0.068000\n",
      "(Iteration 11 / 100) loss: 2.681122\n",
      "(Iteration 12 / 100) loss: 2.606568\n",
      "(Iteration 13 / 100) loss: 2.705914\n",
      "(Iteration 14 / 100) loss: 2.663261\n",
      "(Iteration 15 / 100) loss: 2.611436\n",
      "(Iteration 16 / 100) loss: 2.576914\n",
      "(Iteration 17 / 100) loss: 2.629451\n",
      "(Iteration 18 / 100) loss: 2.578893\n",
      "(Iteration 19 / 100) loss: 2.666737\n",
      "(Iteration 20 / 100) loss: 2.588896\n",
      "(Epoch 2 / 10) train acc: 0.130000; val_acc: 0.126000\n",
      "(Iteration 21 / 100) loss: 2.702517\n",
      "(Iteration 22 / 100) loss: 2.575293\n",
      "(Iteration 23 / 100) loss: 2.460847\n",
      "(Iteration 24 / 100) loss: 2.498744\n",
      "(Iteration 25 / 100) loss: 2.507554\n",
      "(Iteration 26 / 100) loss: 2.620130\n",
      "(Iteration 27 / 100) loss: 2.584044\n",
      "(Iteration 28 / 100) loss: 2.639881\n",
      "(Iteration 29 / 100) loss: 2.582944\n",
      "(Iteration 30 / 100) loss: 2.558717\n",
      "(Epoch 3 / 10) train acc: 0.184000; val_acc: 0.130000\n",
      "(Iteration 31 / 100) loss: 2.561574\n",
      "(Iteration 32 / 100) loss: 2.530818\n",
      "(Iteration 33 / 100) loss: 2.526702\n",
      "(Iteration 34 / 100) loss: 2.544559\n",
      "(Iteration 35 / 100) loss: 2.545947\n",
      "(Iteration 36 / 100) loss: 2.459499\n",
      "(Iteration 37 / 100) loss: 2.468457\n",
      "(Iteration 38 / 100) loss: 2.605383\n",
      "(Iteration 39 / 100) loss: 2.458374\n",
      "(Iteration 40 / 100) loss: 2.495316\n",
      "(Epoch 4 / 10) train acc: 0.212000; val_acc: 0.180000\n",
      "(Iteration 41 / 100) loss: 2.573270\n",
      "(Iteration 42 / 100) loss: 2.426570\n",
      "(Iteration 43 / 100) loss: 2.502512\n",
      "(Iteration 44 / 100) loss: 2.453120\n",
      "(Iteration 45 / 100) loss: 2.411210\n",
      "(Iteration 46 / 100) loss: 2.473420\n",
      "(Iteration 47 / 100) loss: 2.524292\n",
      "(Iteration 48 / 100) loss: 2.542348\n",
      "(Iteration 49 / 100) loss: 2.468187\n",
      "(Iteration 50 / 100) loss: 2.238707\n",
      "(Epoch 5 / 10) train acc: 0.246000; val_acc: 0.154000\n",
      "(Iteration 51 / 100) loss: 2.478514\n",
      "(Iteration 52 / 100) loss: 2.346294\n",
      "(Iteration 53 / 100) loss: 2.288557\n",
      "(Iteration 54 / 100) loss: 2.442524\n",
      "(Iteration 55 / 100) loss: 2.393079\n",
      "(Iteration 56 / 100) loss: 2.465196\n",
      "(Iteration 57 / 100) loss: 2.624695\n",
      "(Iteration 58 / 100) loss: 2.261917\n",
      "(Iteration 59 / 100) loss: 2.363111\n",
      "(Iteration 60 / 100) loss: 2.407672\n",
      "(Epoch 6 / 10) train acc: 0.256000; val_acc: 0.198000\n",
      "(Iteration 61 / 100) loss: 2.311372\n",
      "(Iteration 62 / 100) loss: 2.445563\n",
      "(Iteration 63 / 100) loss: 2.428937\n",
      "(Iteration 64 / 100) loss: 2.445912\n",
      "(Iteration 65 / 100) loss: 2.253174\n",
      "(Iteration 66 / 100) loss: 2.459756\n",
      "(Iteration 67 / 100) loss: 2.377113\n",
      "(Iteration 68 / 100) loss: 2.230418\n",
      "(Iteration 69 / 100) loss: 2.330607\n",
      "(Iteration 70 / 100) loss: 2.328482\n",
      "(Epoch 7 / 10) train acc: 0.246000; val_acc: 0.186000\n",
      "(Iteration 71 / 100) loss: 2.504628\n",
      "(Iteration 72 / 100) loss: 2.370710\n",
      "(Iteration 73 / 100) loss: 2.378502\n",
      "(Iteration 74 / 100) loss: 2.202947\n",
      "(Iteration 75 / 100) loss: 2.442388\n",
      "(Iteration 76 / 100) loss: 2.485069\n",
      "(Iteration 77 / 100) loss: 2.194734\n",
      "(Iteration 78 / 100) loss: 2.305062\n",
      "(Iteration 79 / 100) loss: 2.388706\n",
      "(Iteration 80 / 100) loss: 2.227824\n",
      "(Epoch 8 / 10) train acc: 0.370000; val_acc: 0.228000\n",
      "(Iteration 81 / 100) loss: 2.218566\n",
      "(Iteration 82 / 100) loss: 2.267334\n",
      "(Iteration 83 / 100) loss: 2.380596\n",
      "(Iteration 84 / 100) loss: 2.263266\n",
      "(Iteration 85 / 100) loss: 2.335119\n",
      "(Iteration 86 / 100) loss: 2.268491\n",
      "(Iteration 87 / 100) loss: 2.328667\n",
      "(Iteration 88 / 100) loss: 2.327763\n",
      "(Iteration 89 / 100) loss: 2.218213\n",
      "(Iteration 90 / 100) loss: 2.252984\n",
      "(Epoch 9 / 10) train acc: 0.322000; val_acc: 0.176000\n",
      "(Iteration 91 / 100) loss: 2.340617\n",
      "(Iteration 92 / 100) loss: 2.246288\n",
      "(Iteration 93 / 100) loss: 2.172586\n",
      "(Iteration 94 / 100) loss: 2.275770\n",
      "(Iteration 95 / 100) loss: 2.163713\n",
      "(Iteration 96 / 100) loss: 2.118866\n",
      "(Iteration 97 / 100) loss: 2.241233\n",
      "(Iteration 98 / 100) loss: 2.219552\n",
      "(Iteration 99 / 100) loss: 2.329253\n",
      "(Iteration 100 / 100) loss: 2.261530\n",
      "(Epoch 10 / 10) train acc: 0.360000; val_acc: 0.244000\n",
      "Running weight scale 8 / 20\n",
      "(Iteration 1 / 100) loss: 3.069684\n",
      "(Epoch 0 / 10) train acc: 0.122000; val_acc: 0.096000\n",
      "(Iteration 2 / 100) loss: 2.954852\n",
      "(Iteration 3 / 100) loss: 2.916202\n",
      "(Iteration 4 / 100) loss: 3.012348\n",
      "(Iteration 5 / 100) loss: 3.044521\n",
      "(Iteration 6 / 100) loss: 3.076979\n",
      "(Iteration 7 / 100) loss: 2.965449\n",
      "(Iteration 8 / 100) loss: 3.145100\n",
      "(Iteration 9 / 100) loss: 2.934823\n",
      "(Iteration 10 / 100) loss: 2.968441\n",
      "(Epoch 1 / 10) train acc: 0.168000; val_acc: 0.134000\n",
      "(Iteration 11 / 100) loss: 2.960868\n",
      "(Iteration 12 / 100) loss: 2.901716\n",
      "(Iteration 13 / 100) loss: 2.921503\n",
      "(Iteration 14 / 100) loss: 3.039855\n",
      "(Iteration 15 / 100) loss: 2.928836\n",
      "(Iteration 16 / 100) loss: 2.993553\n",
      "(Iteration 17 / 100) loss: 3.071438\n",
      "(Iteration 18 / 100) loss: 2.949826\n",
      "(Iteration 19 / 100) loss: 2.887838\n",
      "(Iteration 20 / 100) loss: 2.924740\n",
      "(Epoch 2 / 10) train acc: 0.232000; val_acc: 0.194000\n",
      "(Iteration 21 / 100) loss: 2.839685\n",
      "(Iteration 22 / 100) loss: 2.774185\n",
      "(Iteration 23 / 100) loss: 2.834475\n",
      "(Iteration 24 / 100) loss: 2.911974\n",
      "(Iteration 25 / 100) loss: 2.920059\n",
      "(Iteration 26 / 100) loss: 2.922171\n",
      "(Iteration 27 / 100) loss: 2.848093\n",
      "(Iteration 28 / 100) loss: 2.850304\n",
      "(Iteration 29 / 100) loss: 2.863735\n",
      "(Iteration 30 / 100) loss: 2.836084\n",
      "(Epoch 3 / 10) train acc: 0.170000; val_acc: 0.172000\n",
      "(Iteration 31 / 100) loss: 3.039862\n",
      "(Iteration 32 / 100) loss: 2.879215\n",
      "(Iteration 33 / 100) loss: 2.804859\n",
      "(Iteration 34 / 100) loss: 2.850247\n",
      "(Iteration 35 / 100) loss: 2.850160\n",
      "(Iteration 36 / 100) loss: 2.910352\n",
      "(Iteration 37 / 100) loss: 2.941772\n",
      "(Iteration 38 / 100) loss: 2.898496\n",
      "(Iteration 39 / 100) loss: 2.986550\n",
      "(Iteration 40 / 100) loss: 2.853413\n",
      "(Epoch 4 / 10) train acc: 0.242000; val_acc: 0.182000\n",
      "(Iteration 41 / 100) loss: 2.775908\n",
      "(Iteration 42 / 100) loss: 2.888462\n",
      "(Iteration 43 / 100) loss: 2.785995\n",
      "(Iteration 44 / 100) loss: 2.889876\n",
      "(Iteration 45 / 100) loss: 2.948206\n",
      "(Iteration 46 / 100) loss: 2.900264\n",
      "(Iteration 47 / 100) loss: 2.878349\n",
      "(Iteration 48 / 100) loss: 2.785994\n",
      "(Iteration 49 / 100) loss: 2.872291\n",
      "(Iteration 50 / 100) loss: 2.780913\n",
      "(Epoch 5 / 10) train acc: 0.202000; val_acc: 0.180000\n",
      "(Iteration 51 / 100) loss: 2.893676\n",
      "(Iteration 52 / 100) loss: 2.938458\n",
      "(Iteration 53 / 100) loss: 2.926067\n",
      "(Iteration 54 / 100) loss: 2.822432\n",
      "(Iteration 55 / 100) loss: 2.858496\n",
      "(Iteration 56 / 100) loss: 2.915034\n",
      "(Iteration 57 / 100) loss: 2.973524\n",
      "(Iteration 58 / 100) loss: 2.924602\n",
      "(Iteration 59 / 100) loss: 2.956737\n",
      "(Iteration 60 / 100) loss: 2.931781\n",
      "(Epoch 6 / 10) train acc: 0.146000; val_acc: 0.126000\n",
      "(Iteration 61 / 100) loss: 3.083379\n",
      "(Iteration 62 / 100) loss: 3.124675\n",
      "(Iteration 63 / 100) loss: 3.024387\n",
      "(Iteration 64 / 100) loss: 3.055550\n",
      "(Iteration 65 / 100) loss: 3.020158\n",
      "(Iteration 66 / 100) loss: 3.032581\n",
      "(Iteration 67 / 100) loss: 3.124387\n",
      "(Iteration 68 / 100) loss: 3.157740\n",
      "(Iteration 69 / 100) loss: 3.159130\n",
      "(Iteration 70 / 100) loss: 3.137072\n",
      "(Epoch 7 / 10) train acc: 0.134000; val_acc: 0.098000\n",
      "(Iteration 71 / 100) loss: 3.173498\n",
      "(Iteration 72 / 100) loss: 3.039292\n",
      "(Iteration 73 / 100) loss: 3.147280\n",
      "(Iteration 74 / 100) loss: 3.096868\n",
      "(Iteration 75 / 100) loss: 2.977897\n",
      "(Iteration 76 / 100) loss: 3.096517\n",
      "(Iteration 77 / 100) loss: 3.025302\n",
      "(Iteration 78 / 100) loss: 3.177474\n",
      "(Iteration 79 / 100) loss: 3.128033\n",
      "(Iteration 80 / 100) loss: 3.002404\n",
      "(Epoch 8 / 10) train acc: 0.186000; val_acc: 0.142000\n",
      "(Iteration 81 / 100) loss: 3.002721\n",
      "(Iteration 82 / 100) loss: 3.021536\n",
      "(Iteration 83 / 100) loss: 2.998891\n",
      "(Iteration 84 / 100) loss: 3.037778\n",
      "(Iteration 85 / 100) loss: 3.081463\n",
      "(Iteration 86 / 100) loss: 2.971424\n",
      "(Iteration 87 / 100) loss: 2.909023\n",
      "(Iteration 88 / 100) loss: 2.877091\n",
      "(Iteration 89 / 100) loss: 3.000706\n",
      "(Iteration 90 / 100) loss: 2.990626\n",
      "(Epoch 9 / 10) train acc: 0.176000; val_acc: 0.130000\n",
      "(Iteration 91 / 100) loss: 3.046381\n",
      "(Iteration 92 / 100) loss: 3.013298\n",
      "(Iteration 93 / 100) loss: 2.925243\n",
      "(Iteration 94 / 100) loss: 2.969293\n",
      "(Iteration 95 / 100) loss: 2.987942\n",
      "(Iteration 96 / 100) loss: 2.906496\n",
      "(Iteration 97 / 100) loss: 2.869865\n",
      "(Iteration 98 / 100) loss: 2.981319\n",
      "(Iteration 99 / 100) loss: 2.849789\n",
      "(Iteration 100 / 100) loss: 2.958582\n",
      "(Epoch 10 / 10) train acc: 0.234000; val_acc: 0.160000\n",
      "Running weight scale 9 / 20\n",
      "(Iteration 1 / 100) loss: 4.123472\n",
      "(Epoch 0 / 10) train acc: 0.108000; val_acc: 0.110000\n",
      "(Iteration 2 / 100) loss: 4.172938\n",
      "(Iteration 3 / 100) loss: 4.275000\n",
      "(Iteration 4 / 100) loss: 4.107409\n",
      "(Iteration 5 / 100) loss: 4.124283\n",
      "(Iteration 6 / 100) loss: 4.050815\n",
      "(Iteration 7 / 100) loss: 4.140521\n",
      "(Iteration 8 / 100) loss: 4.114785\n",
      "(Iteration 9 / 100) loss: 4.017242\n",
      "(Iteration 10 / 100) loss: 4.025282\n",
      "(Epoch 1 / 10) train acc: 0.174000; val_acc: 0.148000\n",
      "(Iteration 11 / 100) loss: 4.025631\n",
      "(Iteration 12 / 100) loss: 4.038239\n",
      "(Iteration 13 / 100) loss: 3.997378\n",
      "(Iteration 14 / 100) loss: 4.136180\n",
      "(Iteration 15 / 100) loss: 4.046618\n",
      "(Iteration 16 / 100) loss: 4.066120\n",
      "(Iteration 17 / 100) loss: 4.025083\n",
      "(Iteration 18 / 100) loss: 3.967594\n",
      "(Iteration 19 / 100) loss: 3.901174\n",
      "(Iteration 20 / 100) loss: 3.884548\n",
      "(Epoch 2 / 10) train acc: 0.228000; val_acc: 0.156000\n",
      "(Iteration 21 / 100) loss: 4.044187\n",
      "(Iteration 22 / 100) loss: 3.850583\n",
      "(Iteration 23 / 100) loss: 3.920867\n",
      "(Iteration 24 / 100) loss: 3.834215\n",
      "(Iteration 25 / 100) loss: 3.889061\n",
      "(Iteration 26 / 100) loss: 3.907246\n",
      "(Iteration 27 / 100) loss: 4.118856\n",
      "(Iteration 28 / 100) loss: 3.977278\n",
      "(Iteration 29 / 100) loss: 3.891023\n",
      "(Iteration 30 / 100) loss: 3.889497\n",
      "(Epoch 3 / 10) train acc: 0.176000; val_acc: 0.144000\n",
      "(Iteration 31 / 100) loss: 4.204379\n",
      "(Iteration 32 / 100) loss: 4.026328\n",
      "(Iteration 33 / 100) loss: 4.128305\n",
      "(Iteration 34 / 100) loss: 4.223451\n",
      "(Iteration 35 / 100) loss: 3.999776\n",
      "(Iteration 36 / 100) loss: 4.104580\n",
      "(Iteration 37 / 100) loss: 4.004608\n",
      "(Iteration 38 / 100) loss: 4.062820\n",
      "(Iteration 39 / 100) loss: 4.189169\n",
      "(Iteration 40 / 100) loss: 4.096483\n",
      "(Epoch 4 / 10) train acc: 0.212000; val_acc: 0.144000\n",
      "(Iteration 41 / 100) loss: 3.962137\n",
      "(Iteration 42 / 100) loss: 4.255271\n",
      "(Iteration 43 / 100) loss: 4.150267\n",
      "(Iteration 44 / 100) loss: 4.051932\n",
      "(Iteration 45 / 100) loss: 4.141157\n",
      "(Iteration 46 / 100) loss: 3.919308\n",
      "(Iteration 47 / 100) loss: 3.912040\n",
      "(Iteration 48 / 100) loss: 3.910251\n",
      "(Iteration 49 / 100) loss: 4.005515\n",
      "(Iteration 50 / 100) loss: 3.958669\n",
      "(Epoch 5 / 10) train acc: 0.254000; val_acc: 0.156000\n",
      "(Iteration 51 / 100) loss: 4.044905\n",
      "(Iteration 52 / 100) loss: 4.155343\n",
      "(Iteration 53 / 100) loss: 3.989307\n",
      "(Iteration 54 / 100) loss: 4.143621\n",
      "(Iteration 55 / 100) loss: 4.004289\n",
      "(Iteration 56 / 100) loss: 3.877627\n",
      "(Iteration 57 / 100) loss: 3.897307\n",
      "(Iteration 58 / 100) loss: 3.718185\n",
      "(Iteration 59 / 100) loss: 3.800531\n",
      "(Iteration 60 / 100) loss: 4.066566\n",
      "(Epoch 6 / 10) train acc: 0.336000; val_acc: 0.228000\n",
      "(Iteration 61 / 100) loss: 3.906675\n",
      "(Iteration 62 / 100) loss: 3.993009\n",
      "(Iteration 63 / 100) loss: 3.792236\n",
      "(Iteration 64 / 100) loss: 3.890692\n",
      "(Iteration 65 / 100) loss: 3.833517\n",
      "(Iteration 66 / 100) loss: 3.992888\n",
      "(Iteration 67 / 100) loss: 3.926244\n",
      "(Iteration 68 / 100) loss: 3.950614\n",
      "(Iteration 69 / 100) loss: 3.806933\n",
      "(Iteration 70 / 100) loss: 3.821667\n",
      "(Epoch 7 / 10) train acc: 0.342000; val_acc: 0.214000\n",
      "(Iteration 71 / 100) loss: 3.765201\n",
      "(Iteration 72 / 100) loss: 3.771564\n",
      "(Iteration 73 / 100) loss: 3.822739\n",
      "(Iteration 74 / 100) loss: 3.797712\n",
      "(Iteration 75 / 100) loss: 3.800593\n",
      "(Iteration 76 / 100) loss: 3.831798\n",
      "(Iteration 77 / 100) loss: 3.860115\n",
      "(Iteration 78 / 100) loss: 3.997519\n",
      "(Iteration 79 / 100) loss: 3.976283\n",
      "(Iteration 80 / 100) loss: 4.061761\n",
      "(Epoch 8 / 10) train acc: 0.296000; val_acc: 0.176000\n",
      "(Iteration 81 / 100) loss: 3.958481\n",
      "(Iteration 82 / 100) loss: 3.915334\n",
      "(Iteration 83 / 100) loss: 3.879950\n",
      "(Iteration 84 / 100) loss: 3.868708\n",
      "(Iteration 85 / 100) loss: 3.910080\n",
      "(Iteration 86 / 100) loss: 3.996430\n",
      "(Iteration 87 / 100) loss: 3.920726\n",
      "(Iteration 88 / 100) loss: 3.843580\n",
      "(Iteration 89 / 100) loss: 3.907200\n",
      "(Iteration 90 / 100) loss: 3.884669\n",
      "(Epoch 9 / 10) train acc: 0.290000; val_acc: 0.206000\n",
      "(Iteration 91 / 100) loss: 3.975648\n",
      "(Iteration 92 / 100) loss: 3.935508\n",
      "(Iteration 93 / 100) loss: 3.895393\n",
      "(Iteration 94 / 100) loss: 3.936352\n",
      "(Iteration 95 / 100) loss: 3.795554\n",
      "(Iteration 96 / 100) loss: 3.826912\n",
      "(Iteration 97 / 100) loss: 4.001613\n",
      "(Iteration 98 / 100) loss: 3.916254\n",
      "(Iteration 99 / 100) loss: 4.088365\n",
      "(Iteration 100 / 100) loss: 4.024436\n",
      "(Epoch 10 / 10) train acc: 0.190000; val_acc: 0.170000\n",
      "Running weight scale 10 / 20\n",
      "(Iteration 1 / 100) loss: 7.217741\n",
      "(Epoch 0 / 10) train acc: 0.118000; val_acc: 0.110000\n",
      "(Iteration 2 / 100) loss: 7.130045\n",
      "(Iteration 3 / 100) loss: 7.170919\n",
      "(Iteration 4 / 100) loss: 7.160661\n",
      "(Iteration 5 / 100) loss: 7.009225\n",
      "(Iteration 6 / 100) loss: 7.104857\n",
      "(Iteration 7 / 100) loss: 6.925144\n",
      "(Iteration 8 / 100) loss: 7.018672\n",
      "(Iteration 9 / 100) loss: 7.140099\n",
      "(Iteration 10 / 100) loss: 6.831103\n",
      "(Epoch 1 / 10) train acc: 0.180000; val_acc: 0.120000\n",
      "(Iteration 11 / 100) loss: 6.925688\n",
      "(Iteration 12 / 100) loss: 6.946206\n",
      "(Iteration 13 / 100) loss: 7.003640\n",
      "(Iteration 14 / 100) loss: 6.882119\n",
      "(Iteration 15 / 100) loss: 6.794746\n",
      "(Iteration 16 / 100) loss: 6.970325\n",
      "(Iteration 17 / 100) loss: 6.709664\n",
      "(Iteration 18 / 100) loss: 6.945710\n",
      "(Iteration 19 / 100) loss: 6.956417\n",
      "(Iteration 20 / 100) loss: 6.897095\n",
      "(Epoch 2 / 10) train acc: 0.262000; val_acc: 0.176000\n",
      "(Iteration 21 / 100) loss: 6.905757\n",
      "(Iteration 22 / 100) loss: 6.852702\n",
      "(Iteration 23 / 100) loss: 6.555135\n",
      "(Iteration 24 / 100) loss: 6.719011\n",
      "(Iteration 25 / 100) loss: 6.665141\n",
      "(Iteration 26 / 100) loss: 6.665543\n",
      "(Iteration 27 / 100) loss: 6.864373\n",
      "(Iteration 28 / 100) loss: 6.739344\n",
      "(Iteration 29 / 100) loss: 6.628657\n",
      "(Iteration 30 / 100) loss: 6.747360\n",
      "(Epoch 3 / 10) train acc: 0.244000; val_acc: 0.198000\n",
      "(Iteration 31 / 100) loss: 6.862178\n",
      "(Iteration 32 / 100) loss: 6.803681\n",
      "(Iteration 33 / 100) loss: 6.510750\n",
      "(Iteration 34 / 100) loss: 6.742781\n",
      "(Iteration 35 / 100) loss: 6.727277\n",
      "(Iteration 36 / 100) loss: 6.811834\n",
      "(Iteration 37 / 100) loss: 6.680037\n",
      "(Iteration 38 / 100) loss: 6.784993\n",
      "(Iteration 39 / 100) loss: 6.716825\n",
      "(Iteration 40 / 100) loss: 6.909557\n",
      "(Epoch 4 / 10) train acc: 0.284000; val_acc: 0.230000\n",
      "(Iteration 41 / 100) loss: 6.601261\n",
      "(Iteration 42 / 100) loss: 6.582127\n",
      "(Iteration 43 / 100) loss: 6.636886\n",
      "(Iteration 44 / 100) loss: 6.584732\n",
      "(Iteration 45 / 100) loss: 6.590326\n",
      "(Iteration 46 / 100) loss: 6.539786\n",
      "(Iteration 47 / 100) loss: 6.799427\n",
      "(Iteration 48 / 100) loss: 6.600301\n",
      "(Iteration 49 / 100) loss: 6.561678\n",
      "(Iteration 50 / 100) loss: 6.834439\n",
      "(Epoch 5 / 10) train acc: 0.218000; val_acc: 0.184000\n",
      "(Iteration 51 / 100) loss: 6.717893\n",
      "(Iteration 52 / 100) loss: 6.767527\n",
      "(Iteration 53 / 100) loss: 6.791007\n",
      "(Iteration 54 / 100) loss: 6.511812\n",
      "(Iteration 55 / 100) loss: 6.840830\n",
      "(Iteration 56 / 100) loss: 6.623469\n",
      "(Iteration 57 / 100) loss: 6.607602\n",
      "(Iteration 58 / 100) loss: 6.691487\n",
      "(Iteration 59 / 100) loss: 6.554519\n",
      "(Iteration 60 / 100) loss: 6.535791\n",
      "(Epoch 6 / 10) train acc: 0.248000; val_acc: 0.150000\n",
      "(Iteration 61 / 100) loss: 6.891742\n",
      "(Iteration 62 / 100) loss: 6.548023\n",
      "(Iteration 63 / 100) loss: 6.737621\n",
      "(Iteration 64 / 100) loss: 6.680084\n",
      "(Iteration 65 / 100) loss: 6.647804\n",
      "(Iteration 66 / 100) loss: 6.633388\n",
      "(Iteration 67 / 100) loss: 6.388557\n",
      "(Iteration 68 / 100) loss: 6.343040\n",
      "(Iteration 69 / 100) loss: 6.413312\n",
      "(Iteration 70 / 100) loss: 6.458380\n",
      "(Epoch 7 / 10) train acc: 0.262000; val_acc: 0.172000\n",
      "(Iteration 71 / 100) loss: 6.498654\n",
      "(Iteration 72 / 100) loss: 6.469165\n",
      "(Iteration 73 / 100) loss: 6.471629\n",
      "(Iteration 74 / 100) loss: 6.673054\n",
      "(Iteration 75 / 100) loss: 6.565407\n",
      "(Iteration 76 / 100) loss: 6.496736\n",
      "(Iteration 77 / 100) loss: 6.376407\n",
      "(Iteration 78 / 100) loss: 6.593197\n",
      "(Iteration 79 / 100) loss: 6.393054\n",
      "(Iteration 80 / 100) loss: 6.501080\n",
      "(Epoch 8 / 10) train acc: 0.268000; val_acc: 0.176000\n",
      "(Iteration 81 / 100) loss: 6.614027\n",
      "(Iteration 82 / 100) loss: 6.492011\n",
      "(Iteration 83 / 100) loss: 6.623737\n",
      "(Iteration 84 / 100) loss: 6.544952\n",
      "(Iteration 85 / 100) loss: 6.707017\n",
      "(Iteration 86 / 100) loss: 6.526276\n",
      "(Iteration 87 / 100) loss: 6.625918\n",
      "(Iteration 88 / 100) loss: 6.603576\n",
      "(Iteration 89 / 100) loss: 6.584851\n",
      "(Iteration 90 / 100) loss: 6.666330\n",
      "(Epoch 9 / 10) train acc: 0.188000; val_acc: 0.158000\n",
      "(Iteration 91 / 100) loss: 6.714406\n",
      "(Iteration 92 / 100) loss: 6.817007\n",
      "(Iteration 93 / 100) loss: 6.685419\n",
      "(Iteration 94 / 100) loss: 6.619511\n",
      "(Iteration 95 / 100) loss: 6.759968\n",
      "(Iteration 96 / 100) loss: 6.837822\n",
      "(Iteration 97 / 100) loss: 6.833729\n",
      "(Iteration 98 / 100) loss: 6.863142\n",
      "(Iteration 99 / 100) loss: 6.569049\n",
      "(Iteration 100 / 100) loss: 6.663720\n",
      "(Epoch 10 / 10) train acc: 0.180000; val_acc: 0.114000\n",
      "Running weight scale 11 / 20\n",
      "(Iteration 1 / 100) loss: 15.583545\n",
      "(Epoch 0 / 10) train acc: 0.132000; val_acc: 0.112000\n",
      "(Iteration 2 / 100) loss: 15.168439\n",
      "(Iteration 3 / 100) loss: 14.998640\n",
      "(Iteration 4 / 100) loss: 14.960901\n",
      "(Iteration 5 / 100) loss: 14.875432\n",
      "(Iteration 6 / 100) loss: 14.932270\n",
      "(Iteration 7 / 100) loss: 15.054215\n",
      "(Iteration 8 / 100) loss: 15.013810\n",
      "(Iteration 9 / 100) loss: 14.666655\n",
      "(Iteration 10 / 100) loss: 14.805122\n",
      "(Epoch 1 / 10) train acc: 0.188000; val_acc: 0.154000\n",
      "(Iteration 11 / 100) loss: 14.781543\n",
      "(Iteration 12 / 100) loss: 14.747787\n",
      "(Iteration 13 / 100) loss: 14.821359\n",
      "(Iteration 14 / 100) loss: 14.600487\n",
      "(Iteration 15 / 100) loss: 14.974977\n",
      "(Iteration 16 / 100) loss: 14.437740\n",
      "(Iteration 17 / 100) loss: 14.547682\n",
      "(Iteration 18 / 100) loss: 14.554504\n",
      "(Iteration 19 / 100) loss: 14.616066\n",
      "(Iteration 20 / 100) loss: 14.463512\n",
      "(Epoch 2 / 10) train acc: 0.270000; val_acc: 0.186000\n",
      "(Iteration 21 / 100) loss: 14.623505\n",
      "(Iteration 22 / 100) loss: 14.272510\n",
      "(Iteration 23 / 100) loss: 14.209381\n",
      "(Iteration 24 / 100) loss: 14.322181\n",
      "(Iteration 25 / 100) loss: 14.256515\n",
      "(Iteration 26 / 100) loss: 14.251773\n",
      "(Iteration 27 / 100) loss: 14.263215\n",
      "(Iteration 28 / 100) loss: 14.128187\n",
      "(Iteration 29 / 100) loss: 14.111780\n",
      "(Iteration 30 / 100) loss: 13.869184\n",
      "(Epoch 3 / 10) train acc: 0.348000; val_acc: 0.162000\n",
      "(Iteration 31 / 100) loss: 13.973032\n",
      "(Iteration 32 / 100) loss: 13.957397\n",
      "(Iteration 33 / 100) loss: 14.187301\n",
      "(Iteration 34 / 100) loss: 14.163432\n",
      "(Iteration 35 / 100) loss: 14.061029\n",
      "(Iteration 36 / 100) loss: 14.233148\n",
      "(Iteration 37 / 100) loss: 14.351494\n",
      "(Iteration 38 / 100) loss: 14.510908\n",
      "(Iteration 39 / 100) loss: 14.094274\n",
      "(Iteration 40 / 100) loss: 14.091878\n",
      "(Epoch 4 / 10) train acc: 0.340000; val_acc: 0.170000\n",
      "(Iteration 41 / 100) loss: 14.095298\n",
      "(Iteration 42 / 100) loss: 14.064515\n",
      "(Iteration 43 / 100) loss: 14.162446\n",
      "(Iteration 44 / 100) loss: 14.135458\n",
      "(Iteration 45 / 100) loss: 13.925629\n",
      "(Iteration 46 / 100) loss: 14.296311\n",
      "(Iteration 47 / 100) loss: 13.880233\n",
      "(Iteration 48 / 100) loss: 13.867766\n",
      "(Iteration 49 / 100) loss: 13.979499\n",
      "(Iteration 50 / 100) loss: 13.963014\n",
      "(Epoch 5 / 10) train acc: 0.332000; val_acc: 0.202000\n",
      "(Iteration 51 / 100) loss: 13.704410\n",
      "(Iteration 52 / 100) loss: 14.086625\n",
      "(Iteration 53 / 100) loss: 14.178299\n",
      "(Iteration 54 / 100) loss: 13.746024\n",
      "(Iteration 55 / 100) loss: 13.649174\n",
      "(Iteration 56 / 100) loss: 13.699216\n",
      "(Iteration 57 / 100) loss: 13.850393\n",
      "(Iteration 58 / 100) loss: 13.687044\n",
      "(Iteration 59 / 100) loss: 13.732916\n",
      "(Iteration 60 / 100) loss: 13.575971\n",
      "(Epoch 6 / 10) train acc: 0.422000; val_acc: 0.234000\n",
      "(Iteration 61 / 100) loss: 13.235859\n",
      "(Iteration 62 / 100) loss: 13.683404\n",
      "(Iteration 63 / 100) loss: 13.485782\n",
      "(Iteration 64 / 100) loss: 13.490045\n",
      "(Iteration 65 / 100) loss: 13.454315\n",
      "(Iteration 66 / 100) loss: 13.653587\n",
      "(Iteration 67 / 100) loss: 13.393156\n",
      "(Iteration 68 / 100) loss: 13.204611\n",
      "(Iteration 69 / 100) loss: 13.178547\n",
      "(Iteration 70 / 100) loss: 13.452002\n",
      "(Epoch 7 / 10) train acc: 0.458000; val_acc: 0.228000\n",
      "(Iteration 71 / 100) loss: 13.690204\n",
      "(Iteration 72 / 100) loss: 13.061768\n",
      "(Iteration 73 / 100) loss: 13.298076\n",
      "(Iteration 74 / 100) loss: 13.183263\n",
      "(Iteration 75 / 100) loss: 13.275367\n",
      "(Iteration 76 / 100) loss: 13.152540\n",
      "(Iteration 77 / 100) loss: 13.355667\n",
      "(Iteration 78 / 100) loss: 13.054173\n",
      "(Iteration 79 / 100) loss: 13.240935\n",
      "(Iteration 80 / 100) loss: 13.172525\n",
      "(Epoch 8 / 10) train acc: 0.474000; val_acc: 0.222000\n",
      "(Iteration 81 / 100) loss: 13.138647\n",
      "(Iteration 82 / 100) loss: 13.138364\n",
      "(Iteration 83 / 100) loss: 13.163351\n",
      "(Iteration 84 / 100) loss: 13.127287\n",
      "(Iteration 85 / 100) loss: 13.212314\n",
      "(Iteration 86 / 100) loss: 13.065857\n",
      "(Iteration 87 / 100) loss: 13.071860\n",
      "(Iteration 88 / 100) loss: 12.914034\n",
      "(Iteration 89 / 100) loss: 13.198881\n",
      "(Iteration 90 / 100) loss: 13.037240\n",
      "(Epoch 9 / 10) train acc: 0.496000; val_acc: 0.244000\n",
      "(Iteration 91 / 100) loss: 13.075147\n",
      "(Iteration 92 / 100) loss: 12.969261\n",
      "(Iteration 93 / 100) loss: 12.932812\n",
      "(Iteration 94 / 100) loss: 12.947410\n",
      "(Iteration 95 / 100) loss: 12.859239\n",
      "(Iteration 96 / 100) loss: 12.939727\n",
      "(Iteration 97 / 100) loss: 12.816215\n",
      "(Iteration 98 / 100) loss: 13.061111\n",
      "(Iteration 99 / 100) loss: 12.865414\n",
      "(Iteration 100 / 100) loss: 12.655025\n",
      "(Epoch 10 / 10) train acc: 0.500000; val_acc: 0.248000\n",
      "Running weight scale 12 / 20\n",
      "(Iteration 1 / 100) loss: 39.017883\n",
      "(Epoch 0 / 10) train acc: 0.094000; val_acc: 0.090000\n",
      "(Iteration 2 / 100) loss: 37.254654\n",
      "(Iteration 3 / 100) loss: 37.075327\n",
      "(Iteration 4 / 100) loss: 36.208461\n",
      "(Iteration 5 / 100) loss: 35.785470\n",
      "(Iteration 6 / 100) loss: 35.571293\n",
      "(Iteration 7 / 100) loss: 35.524255\n",
      "(Iteration 8 / 100) loss: 36.353788\n",
      "(Iteration 9 / 100) loss: 35.686518\n",
      "(Iteration 10 / 100) loss: 35.683676\n",
      "(Epoch 1 / 10) train acc: 0.184000; val_acc: 0.130000\n",
      "(Iteration 11 / 100) loss: 35.997636\n",
      "(Iteration 12 / 100) loss: 35.125630\n",
      "(Iteration 13 / 100) loss: 35.420058\n",
      "(Iteration 14 / 100) loss: 35.697259\n",
      "(Iteration 15 / 100) loss: 35.196710\n",
      "(Iteration 16 / 100) loss: 35.307194\n",
      "(Iteration 17 / 100) loss: 34.696631\n",
      "(Iteration 18 / 100) loss: 34.985356\n",
      "(Iteration 19 / 100) loss: 34.796269\n",
      "(Iteration 20 / 100) loss: 34.659457\n",
      "(Epoch 2 / 10) train acc: 0.228000; val_acc: 0.142000\n",
      "(Iteration 21 / 100) loss: 34.848533\n",
      "(Iteration 22 / 100) loss: 35.151234\n",
      "(Iteration 23 / 100) loss: 34.641876\n",
      "(Iteration 24 / 100) loss: 34.815574\n",
      "(Iteration 25 / 100) loss: 34.106115\n",
      "(Iteration 26 / 100) loss: 34.411248\n",
      "(Iteration 27 / 100) loss: 34.373940\n",
      "(Iteration 28 / 100) loss: 34.059157\n",
      "(Iteration 29 / 100) loss: 34.277384\n",
      "(Iteration 30 / 100) loss: 34.065092\n",
      "(Epoch 3 / 10) train acc: 0.326000; val_acc: 0.170000\n",
      "(Iteration 31 / 100) loss: 34.028314\n",
      "(Iteration 32 / 100) loss: 33.926165\n",
      "(Iteration 33 / 100) loss: 33.680736\n",
      "(Iteration 34 / 100) loss: 33.849979\n",
      "(Iteration 35 / 100) loss: 33.837910\n",
      "(Iteration 36 / 100) loss: 33.721310\n",
      "(Iteration 37 / 100) loss: 33.822837\n",
      "(Iteration 38 / 100) loss: 33.595048\n",
      "(Iteration 39 / 100) loss: 33.765752\n",
      "(Iteration 40 / 100) loss: 33.209128\n",
      "(Epoch 4 / 10) train acc: 0.450000; val_acc: 0.180000\n",
      "(Iteration 41 / 100) loss: 33.409193\n",
      "(Iteration 42 / 100) loss: 33.318468\n",
      "(Iteration 43 / 100) loss: 33.229796\n",
      "(Iteration 44 / 100) loss: 33.055209\n",
      "(Iteration 45 / 100) loss: 33.007701\n",
      "(Iteration 46 / 100) loss: 32.757875\n",
      "(Iteration 47 / 100) loss: 32.599632\n",
      "(Iteration 48 / 100) loss: 32.738969\n",
      "(Iteration 49 / 100) loss: 32.739952\n",
      "(Iteration 50 / 100) loss: 32.694585\n",
      "(Epoch 5 / 10) train acc: 0.512000; val_acc: 0.218000\n",
      "(Iteration 51 / 100) loss: 32.578825\n",
      "(Iteration 52 / 100) loss: 32.547668\n",
      "(Iteration 53 / 100) loss: 32.606622\n",
      "(Iteration 54 / 100) loss: 32.433543\n",
      "(Iteration 55 / 100) loss: 32.252554\n",
      "(Iteration 56 / 100) loss: 32.452155\n",
      "(Iteration 57 / 100) loss: 32.304797\n",
      "(Iteration 58 / 100) loss: 32.430730\n",
      "(Iteration 59 / 100) loss: 32.092464\n",
      "(Iteration 60 / 100) loss: 31.944594\n",
      "(Epoch 6 / 10) train acc: 0.500000; val_acc: 0.236000\n",
      "(Iteration 61 / 100) loss: 32.077802\n",
      "(Iteration 62 / 100) loss: 32.329241\n",
      "(Iteration 63 / 100) loss: 32.244398\n",
      "(Iteration 64 / 100) loss: 31.976225\n",
      "(Iteration 65 / 100) loss: 31.937892\n",
      "(Iteration 66 / 100) loss: 31.737047\n",
      "(Iteration 67 / 100) loss: 32.250418\n",
      "(Iteration 68 / 100) loss: 31.955010\n",
      "(Iteration 69 / 100) loss: 31.873558\n",
      "(Iteration 70 / 100) loss: 31.809515\n",
      "(Epoch 7 / 10) train acc: 0.452000; val_acc: 0.226000\n",
      "(Iteration 71 / 100) loss: 32.173417\n",
      "(Iteration 72 / 100) loss: 31.811495\n",
      "(Iteration 73 / 100) loss: 31.899970\n",
      "(Iteration 74 / 100) loss: 31.972779\n",
      "(Iteration 75 / 100) loss: 31.403964\n",
      "(Iteration 76 / 100) loss: 31.408627\n",
      "(Iteration 77 / 100) loss: 31.524494\n",
      "(Iteration 78 / 100) loss: 31.228623\n",
      "(Iteration 79 / 100) loss: 31.413641\n",
      "(Iteration 80 / 100) loss: 30.893577\n",
      "(Epoch 8 / 10) train acc: 0.524000; val_acc: 0.222000\n",
      "(Iteration 81 / 100) loss: 31.009980\n",
      "(Iteration 82 / 100) loss: 31.283395\n",
      "(Iteration 83 / 100) loss: 30.970994\n",
      "(Iteration 84 / 100) loss: 31.073562\n",
      "(Iteration 85 / 100) loss: 31.387351\n",
      "(Iteration 86 / 100) loss: 31.006014\n",
      "(Iteration 87 / 100) loss: 30.970041\n",
      "(Iteration 88 / 100) loss: 31.000629\n",
      "(Iteration 89 / 100) loss: 30.930714\n",
      "(Iteration 90 / 100) loss: 30.716854\n",
      "(Epoch 9 / 10) train acc: 0.504000; val_acc: 0.238000\n",
      "(Iteration 91 / 100) loss: 30.708933\n",
      "(Iteration 92 / 100) loss: 30.575702\n",
      "(Iteration 93 / 100) loss: 30.812655\n",
      "(Iteration 94 / 100) loss: 30.656176\n",
      "(Iteration 95 / 100) loss: 30.547095\n",
      "(Iteration 96 / 100) loss: 30.687344\n",
      "(Iteration 97 / 100) loss: 30.379608\n",
      "(Iteration 98 / 100) loss: 30.475922\n",
      "(Iteration 99 / 100) loss: 30.628152\n",
      "(Iteration 100 / 100) loss: 30.441327\n",
      "(Epoch 10 / 10) train acc: 0.452000; val_acc: 0.224000\n",
      "Running weight scale 13 / 20\n",
      "(Iteration 1 / 100) loss: 93.240374\n",
      "(Epoch 0 / 10) train acc: 0.100000; val_acc: 0.114000\n",
      "(Iteration 2 / 100) loss: 92.354048\n",
      "(Iteration 3 / 100) loss: 91.265131\n",
      "(Iteration 4 / 100) loss: 91.466283\n",
      "(Iteration 5 / 100) loss: 90.647543\n",
      "(Iteration 6 / 100) loss: 89.453047\n",
      "(Iteration 7 / 100) loss: 90.788523\n",
      "(Iteration 8 / 100) loss: 91.008315\n",
      "(Iteration 9 / 100) loss: 90.100634\n",
      "(Iteration 10 / 100) loss: 89.756376\n",
      "(Epoch 1 / 10) train acc: 0.176000; val_acc: 0.136000\n",
      "(Iteration 11 / 100) loss: 89.681947\n",
      "(Iteration 12 / 100) loss: 89.956567\n",
      "(Iteration 13 / 100) loss: 89.648799\n",
      "(Iteration 14 / 100) loss: 88.689157\n",
      "(Iteration 15 / 100) loss: 88.629880\n",
      "(Iteration 16 / 100) loss: 89.339296\n",
      "(Iteration 17 / 100) loss: 88.217070\n",
      "(Iteration 18 / 100) loss: 88.919538\n",
      "(Iteration 19 / 100) loss: 88.749241\n",
      "(Iteration 20 / 100) loss: 87.310611\n",
      "(Epoch 2 / 10) train acc: 0.328000; val_acc: 0.132000\n",
      "(Iteration 21 / 100) loss: 87.357759\n",
      "(Iteration 22 / 100) loss: 87.462587\n",
      "(Iteration 23 / 100) loss: 88.207880\n",
      "(Iteration 24 / 100) loss: 87.314105\n",
      "(Iteration 25 / 100) loss: 86.967610\n",
      "(Iteration 26 / 100) loss: 87.238568\n",
      "(Iteration 27 / 100) loss: 86.649347\n",
      "(Iteration 28 / 100) loss: 86.599167\n",
      "(Iteration 29 / 100) loss: 86.795373\n",
      "(Iteration 30 / 100) loss: 86.964596\n",
      "(Epoch 3 / 10) train acc: 0.394000; val_acc: 0.160000\n",
      "(Iteration 31 / 100) loss: 85.809698\n",
      "(Iteration 32 / 100) loss: 85.982244\n",
      "(Iteration 33 / 100) loss: 85.539800\n",
      "(Iteration 34 / 100) loss: 85.758175\n",
      "(Iteration 35 / 100) loss: 85.632829\n",
      "(Iteration 36 / 100) loss: 85.696647\n",
      "(Iteration 37 / 100) loss: 84.936634\n",
      "(Iteration 38 / 100) loss: 85.283946\n",
      "(Iteration 39 / 100) loss: 84.955436\n",
      "(Iteration 40 / 100) loss: 84.297856\n",
      "(Epoch 4 / 10) train acc: 0.506000; val_acc: 0.160000\n",
      "(Iteration 41 / 100) loss: 84.624214\n",
      "(Iteration 42 / 100) loss: 84.682802\n",
      "(Iteration 43 / 100) loss: 84.471030\n",
      "(Iteration 44 / 100) loss: 83.633385\n",
      "(Iteration 45 / 100) loss: 83.622006\n",
      "(Iteration 46 / 100) loss: 83.761603\n",
      "(Iteration 47 / 100) loss: 83.714506\n",
      "(Iteration 48 / 100) loss: 83.677252\n",
      "(Iteration 49 / 100) loss: 83.518817\n",
      "(Iteration 50 / 100) loss: 83.195173\n",
      "(Epoch 5 / 10) train acc: 0.626000; val_acc: 0.160000\n",
      "(Iteration 51 / 100) loss: 83.322202\n",
      "(Iteration 52 / 100) loss: 82.911629\n",
      "(Iteration 53 / 100) loss: 82.600373\n",
      "(Iteration 54 / 100) loss: 82.405872\n",
      "(Iteration 55 / 100) loss: 82.499622\n",
      "(Iteration 56 / 100) loss: 82.212422\n",
      "(Iteration 57 / 100) loss: 82.242298\n",
      "(Iteration 58 / 100) loss: 82.216856\n",
      "(Iteration 59 / 100) loss: 82.125743\n",
      "(Iteration 60 / 100) loss: 82.011731\n",
      "(Epoch 6 / 10) train acc: 0.620000; val_acc: 0.168000\n",
      "(Iteration 61 / 100) loss: 81.525833\n",
      "(Iteration 62 / 100) loss: 81.413553\n",
      "(Iteration 63 / 100) loss: 81.169715\n",
      "(Iteration 64 / 100) loss: 81.542118\n",
      "(Iteration 65 / 100) loss: 80.904138\n",
      "(Iteration 66 / 100) loss: 80.973576\n",
      "(Iteration 67 / 100) loss: 80.520136\n",
      "(Iteration 68 / 100) loss: 80.597982\n",
      "(Iteration 69 / 100) loss: 80.448884\n",
      "(Iteration 70 / 100) loss: 80.070473\n",
      "(Epoch 7 / 10) train acc: 0.782000; val_acc: 0.164000\n",
      "(Iteration 71 / 100) loss: 80.040900\n",
      "(Iteration 72 / 100) loss: 80.002569\n",
      "(Iteration 73 / 100) loss: 80.030021\n",
      "(Iteration 74 / 100) loss: 79.674320\n",
      "(Iteration 75 / 100) loss: 79.522827\n",
      "(Iteration 76 / 100) loss: 79.337877\n",
      "(Iteration 77 / 100) loss: 79.310174\n",
      "(Iteration 78 / 100) loss: 79.057780\n",
      "(Iteration 79 / 100) loss: 78.794823\n",
      "(Iteration 80 / 100) loss: 78.724938\n",
      "(Epoch 8 / 10) train acc: 0.870000; val_acc: 0.156000\n",
      "(Iteration 81 / 100) loss: 78.733699\n",
      "(Iteration 82 / 100) loss: 78.446579\n",
      "(Iteration 83 / 100) loss: 78.383745\n",
      "(Iteration 84 / 100) loss: 78.134456\n",
      "(Iteration 85 / 100) loss: 78.256460\n",
      "(Iteration 86 / 100) loss: 77.850157\n",
      "(Iteration 87 / 100) loss: 77.682561\n",
      "(Iteration 88 / 100) loss: 77.753932\n",
      "(Iteration 89 / 100) loss: 77.709254\n",
      "(Iteration 90 / 100) loss: 77.288284\n",
      "(Epoch 9 / 10) train acc: 0.908000; val_acc: 0.194000\n",
      "(Iteration 91 / 100) loss: 77.222558\n",
      "(Iteration 92 / 100) loss: 77.051391\n",
      "(Iteration 93 / 100) loss: 77.019895\n",
      "(Iteration 94 / 100) loss: 76.766078\n",
      "(Iteration 95 / 100) loss: 76.877671\n",
      "(Iteration 96 / 100) loss: 76.595657\n",
      "(Iteration 97 / 100) loss: 76.244928\n",
      "(Iteration 98 / 100) loss: 76.283512\n",
      "(Iteration 99 / 100) loss: 76.066886\n",
      "(Iteration 100 / 100) loss: 75.995057\n",
      "(Epoch 10 / 10) train acc: 0.922000; val_acc: 0.198000\n",
      "Running weight scale 14 / 20\n",
      "(Iteration 1 / 100) loss: 237.922044\n",
      "(Epoch 0 / 10) train acc: 0.126000; val_acc: 0.116000\n",
      "(Iteration 2 / 100) loss: 237.346919\n",
      "(Iteration 3 / 100) loss: 236.579680\n",
      "(Iteration 4 / 100) loss: 235.303881\n",
      "(Iteration 5 / 100) loss: 232.968834\n",
      "(Iteration 6 / 100) loss: 233.268490\n",
      "(Iteration 7 / 100) loss: 234.344095\n",
      "(Iteration 8 / 100) loss: 231.868359\n",
      "(Iteration 9 / 100) loss: 231.992663\n",
      "(Iteration 10 / 100) loss: 231.197417\n",
      "(Epoch 1 / 10) train acc: 0.188000; val_acc: 0.130000\n",
      "(Iteration 11 / 100) loss: 231.128639\n",
      "(Iteration 12 / 100) loss: 229.768380\n",
      "(Iteration 13 / 100) loss: 230.827096\n",
      "(Iteration 14 / 100) loss: 229.958761\n",
      "(Iteration 15 / 100) loss: 230.951590\n",
      "(Iteration 16 / 100) loss: 229.995159\n",
      "(Iteration 17 / 100) loss: 229.785337\n",
      "(Iteration 18 / 100) loss: 228.205515\n",
      "(Iteration 19 / 100) loss: 228.464865\n",
      "(Iteration 20 / 100) loss: 228.140343\n",
      "(Epoch 2 / 10) train acc: 0.286000; val_acc: 0.138000\n",
      "(Iteration 21 / 100) loss: 227.554448\n",
      "(Iteration 22 / 100) loss: 228.317355\n",
      "(Iteration 23 / 100) loss: 227.080967\n",
      "(Iteration 24 / 100) loss: 226.536740\n",
      "(Iteration 25 / 100) loss: 227.378299\n",
      "(Iteration 26 / 100) loss: 226.350472\n",
      "(Iteration 27 / 100) loss: 225.468969\n",
      "(Iteration 28 / 100) loss: 225.064425\n",
      "(Iteration 29 / 100) loss: 225.011347\n",
      "(Iteration 30 / 100) loss: 224.680727\n",
      "(Epoch 3 / 10) train acc: 0.412000; val_acc: 0.156000\n",
      "(Iteration 31 / 100) loss: 224.177548\n",
      "(Iteration 32 / 100) loss: 223.496565\n",
      "(Iteration 33 / 100) loss: 223.175960\n",
      "(Iteration 34 / 100) loss: 222.758754\n",
      "(Iteration 35 / 100) loss: 222.779299\n",
      "(Iteration 36 / 100) loss: 221.388026\n",
      "(Iteration 37 / 100) loss: 222.417795\n",
      "(Iteration 38 / 100) loss: 221.952217\n",
      "(Iteration 39 / 100) loss: 221.360374\n",
      "(Iteration 40 / 100) loss: 221.223725\n",
      "(Epoch 4 / 10) train acc: 0.432000; val_acc: 0.164000\n",
      "(Iteration 41 / 100) loss: 220.421946\n",
      "(Iteration 42 / 100) loss: 220.910524\n",
      "(Iteration 43 / 100) loss: 219.958517\n",
      "(Iteration 44 / 100) loss: 220.706488\n",
      "(Iteration 45 / 100) loss: 219.544616\n",
      "(Iteration 46 / 100) loss: 219.392447\n",
      "(Iteration 47 / 100) loss: 218.694914\n",
      "(Iteration 48 / 100) loss: 218.577493\n",
      "(Iteration 49 / 100) loss: 218.927765\n",
      "(Iteration 50 / 100) loss: 217.893828\n",
      "(Epoch 5 / 10) train acc: 0.614000; val_acc: 0.178000\n",
      "(Iteration 51 / 100) loss: 218.302976\n",
      "(Iteration 52 / 100) loss: 217.833314\n",
      "(Iteration 53 / 100) loss: 217.057937\n",
      "(Iteration 54 / 100) loss: 216.881216\n",
      "(Iteration 55 / 100) loss: 216.167601\n",
      "(Iteration 56 / 100) loss: 216.357503\n",
      "(Iteration 57 / 100) loss: 216.130968\n",
      "(Iteration 58 / 100) loss: 216.244747\n",
      "(Iteration 59 / 100) loss: 215.760496\n",
      "(Iteration 60 / 100) loss: 215.374646\n",
      "(Epoch 6 / 10) train acc: 0.622000; val_acc: 0.160000\n",
      "(Iteration 61 / 100) loss: 214.775423\n",
      "(Iteration 62 / 100) loss: 214.850834\n",
      "(Iteration 63 / 100) loss: 214.003557\n",
      "(Iteration 64 / 100) loss: 213.532535\n",
      "(Iteration 65 / 100) loss: 213.526357\n",
      "(Iteration 66 / 100) loss: 213.283319\n",
      "(Iteration 67 / 100) loss: 213.484104\n",
      "(Iteration 68 / 100) loss: 212.350392\n",
      "(Iteration 69 / 100) loss: 212.069452\n",
      "(Iteration 70 / 100) loss: 211.982534\n",
      "(Epoch 7 / 10) train acc: 0.766000; val_acc: 0.192000\n",
      "(Iteration 71 / 100) loss: 211.962340\n",
      "(Iteration 72 / 100) loss: 211.790106\n",
      "(Iteration 73 / 100) loss: 211.216633\n",
      "(Iteration 74 / 100) loss: 210.874890\n",
      "(Iteration 75 / 100) loss: 210.553513\n",
      "(Iteration 76 / 100) loss: 210.033008\n",
      "(Iteration 77 / 100) loss: 209.744484\n",
      "(Iteration 78 / 100) loss: 210.238147\n",
      "(Iteration 79 / 100) loss: 209.190898\n",
      "(Iteration 80 / 100) loss: 208.700094\n",
      "(Epoch 8 / 10) train acc: 0.854000; val_acc: 0.186000\n",
      "(Iteration 81 / 100) loss: 208.625388\n",
      "(Iteration 82 / 100) loss: 208.683127\n",
      "(Iteration 83 / 100) loss: 208.183190\n",
      "(Iteration 84 / 100) loss: 207.791504\n",
      "(Iteration 85 / 100) loss: 207.389749\n",
      "(Iteration 86 / 100) loss: 207.106173\n",
      "(Iteration 87 / 100) loss: 207.249214\n",
      "(Iteration 88 / 100) loss: 207.082311\n",
      "(Iteration 89 / 100) loss: 206.189661\n",
      "(Iteration 90 / 100) loss: 206.204268\n",
      "(Epoch 9 / 10) train acc: 0.870000; val_acc: 0.210000\n",
      "(Iteration 91 / 100) loss: 205.913072\n",
      "(Iteration 92 / 100) loss: 205.610169\n",
      "(Iteration 93 / 100) loss: 204.987722\n",
      "(Iteration 94 / 100) loss: 204.724699\n",
      "(Iteration 95 / 100) loss: 204.819965\n",
      "(Iteration 96 / 100) loss: 204.175125\n",
      "(Iteration 97 / 100) loss: 203.848634\n",
      "(Iteration 98 / 100) loss: 203.820540\n",
      "(Iteration 99 / 100) loss: 203.379077\n",
      "(Iteration 100 / 100) loss: 203.006016\n",
      "(Epoch 10 / 10) train acc: 0.862000; val_acc: 0.174000\n",
      "Running weight scale 15 / 20\n",
      "(Iteration 1 / 100) loss: 616.823652\n",
      "(Epoch 0 / 10) train acc: 0.092000; val_acc: 0.082000\n",
      "(Iteration 2 / 100) loss: 618.931444\n",
      "(Iteration 3 / 100) loss: 615.559134\n",
      "(Iteration 4 / 100) loss: 615.652004\n",
      "(Iteration 5 / 100) loss: 614.941533\n",
      "(Iteration 6 / 100) loss: 613.554466\n",
      "(Iteration 7 / 100) loss: 611.764908\n",
      "(Iteration 8 / 100) loss: 613.118662\n",
      "(Iteration 9 / 100) loss: 610.548061\n",
      "(Iteration 10 / 100) loss: 610.129246\n",
      "(Epoch 1 / 10) train acc: 0.146000; val_acc: 0.114000\n",
      "(Iteration 11 / 100) loss: 609.317801\n",
      "(Iteration 12 / 100) loss: 610.068300\n",
      "(Iteration 13 / 100) loss: 608.104796\n",
      "(Iteration 14 / 100) loss: 608.483530\n",
      "(Iteration 15 / 100) loss: 607.331247\n",
      "(Iteration 16 / 100) loss: 605.727184\n",
      "(Iteration 17 / 100) loss: 605.489256\n",
      "(Iteration 18 / 100) loss: 604.371359\n",
      "(Iteration 19 / 100) loss: 604.080247\n",
      "(Iteration 20 / 100) loss: 603.868145\n",
      "(Epoch 2 / 10) train acc: 0.208000; val_acc: 0.114000\n",
      "(Iteration 21 / 100) loss: 602.607090\n",
      "(Iteration 22 / 100) loss: 603.687674\n",
      "(Iteration 23 / 100) loss: 600.410406\n",
      "(Iteration 24 / 100) loss: 602.791896\n",
      "(Iteration 25 / 100) loss: 601.206525\n",
      "(Iteration 26 / 100) loss: 599.420099\n",
      "(Iteration 27 / 100) loss: 598.968832\n",
      "(Iteration 28 / 100) loss: 598.132203\n",
      "(Iteration 29 / 100) loss: 598.014847\n",
      "(Iteration 30 / 100) loss: 595.756043\n",
      "(Epoch 3 / 10) train acc: 0.244000; val_acc: 0.142000\n",
      "(Iteration 31 / 100) loss: 595.427079\n",
      "(Iteration 32 / 100) loss: 595.928671\n",
      "(Iteration 33 / 100) loss: 595.468944\n",
      "(Iteration 34 / 100) loss: 594.208238\n",
      "(Iteration 35 / 100) loss: 594.431577\n",
      "(Iteration 36 / 100) loss: 594.367318\n",
      "(Iteration 37 / 100) loss: 593.316995\n",
      "(Iteration 38 / 100) loss: 591.211069\n",
      "(Iteration 39 / 100) loss: 591.585572\n",
      "(Iteration 40 / 100) loss: 590.503003\n",
      "(Epoch 4 / 10) train acc: 0.338000; val_acc: 0.144000\n",
      "(Iteration 41 / 100) loss: 590.248223\n",
      "(Iteration 42 / 100) loss: 588.293447\n",
      "(Iteration 43 / 100) loss: 588.376743\n",
      "(Iteration 44 / 100) loss: 588.914384\n",
      "(Iteration 45 / 100) loss: 586.125032\n",
      "(Iteration 46 / 100) loss: 587.239975\n",
      "(Iteration 47 / 100) loss: 588.345104\n",
      "(Iteration 48 / 100) loss: 585.780876\n",
      "(Iteration 49 / 100) loss: 585.452825\n",
      "(Iteration 50 / 100) loss: 584.608855\n",
      "(Epoch 5 / 10) train acc: 0.362000; val_acc: 0.142000\n",
      "(Iteration 51 / 100) loss: 584.832903\n",
      "(Iteration 52 / 100) loss: 582.622671\n",
      "(Iteration 53 / 100) loss: 581.878725\n",
      "(Iteration 54 / 100) loss: 580.987518\n",
      "(Iteration 55 / 100) loss: 581.518578\n",
      "(Iteration 56 / 100) loss: 580.395408\n",
      "(Iteration 57 / 100) loss: 580.240675\n",
      "(Iteration 58 / 100) loss: 580.019722\n",
      "(Iteration 59 / 100) loss: 578.989867\n",
      "(Iteration 60 / 100) loss: 578.697082\n",
      "(Epoch 6 / 10) train acc: 0.448000; val_acc: 0.148000\n",
      "(Iteration 61 / 100) loss: 578.054620\n",
      "(Iteration 62 / 100) loss: 577.709233\n",
      "(Iteration 63 / 100) loss: 577.479573\n",
      "(Iteration 64 / 100) loss: 575.406743\n",
      "(Iteration 65 / 100) loss: 574.504588\n",
      "(Iteration 66 / 100) loss: 575.095284\n",
      "(Iteration 67 / 100) loss: 573.688096\n",
      "(Iteration 68 / 100) loss: 573.419741\n",
      "(Iteration 69 / 100) loss: 572.273419\n",
      "(Iteration 70 / 100) loss: 572.256141\n",
      "(Epoch 7 / 10) train acc: 0.508000; val_acc: 0.132000\n",
      "(Iteration 71 / 100) loss: 571.600512\n",
      "(Iteration 72 / 100) loss: 570.927894\n",
      "(Iteration 73 / 100) loss: 569.542140\n",
      "(Iteration 74 / 100) loss: 569.382757\n",
      "(Iteration 75 / 100) loss: 569.414844\n",
      "(Iteration 76 / 100) loss: 568.992230\n",
      "(Iteration 77 / 100) loss: 568.467787\n",
      "(Iteration 78 / 100) loss: 567.681906\n",
      "(Iteration 79 / 100) loss: 566.879765\n",
      "(Iteration 80 / 100) loss: 566.372956\n",
      "(Epoch 8 / 10) train acc: 0.606000; val_acc: 0.148000\n",
      "(Iteration 81 / 100) loss: 566.201997\n",
      "(Iteration 82 / 100) loss: 565.229352\n",
      "(Iteration 83 / 100) loss: 564.937903\n",
      "(Iteration 84 / 100) loss: 563.322259\n",
      "(Iteration 85 / 100) loss: 562.139832\n",
      "(Iteration 86 / 100) loss: 562.561128\n",
      "(Iteration 87 / 100) loss: 562.337917\n",
      "(Iteration 88 / 100) loss: 561.065235\n",
      "(Iteration 89 / 100) loss: 561.719149\n",
      "(Iteration 90 / 100) loss: 560.509606\n",
      "(Epoch 9 / 10) train acc: 0.554000; val_acc: 0.166000\n",
      "(Iteration 91 / 100) loss: 560.864747\n",
      "(Iteration 92 / 100) loss: 558.610379\n",
      "(Iteration 93 / 100) loss: 557.820200\n",
      "(Iteration 94 / 100) loss: 559.245719\n",
      "(Iteration 95 / 100) loss: 556.907697\n",
      "(Iteration 96 / 100) loss: 557.222297\n",
      "(Iteration 97 / 100) loss: 556.458305\n",
      "(Iteration 98 / 100) loss: 555.178929\n",
      "(Iteration 99 / 100) loss: 555.019519\n",
      "(Iteration 100 / 100) loss: 554.436105\n",
      "(Epoch 10 / 10) train acc: 0.718000; val_acc: 0.146000\n",
      "Running weight scale 16 / 20\n",
      "(Iteration 1 / 100) loss: 1628.104454\n",
      "(Epoch 0 / 10) train acc: 0.112000; val_acc: 0.100000\n",
      "(Iteration 2 / 100) loss: 1631.981966\n",
      "(Iteration 3 / 100) loss: 1621.491090\n",
      "(Iteration 4 / 100) loss: 1622.917196\n",
      "(Iteration 5 / 100) loss: 1614.669357\n",
      "(Iteration 6 / 100) loss: 1615.996360\n",
      "(Iteration 7 / 100) loss: 1615.377657\n",
      "(Iteration 8 / 100) loss: 1617.772699\n",
      "(Iteration 9 / 100) loss: 1613.624280\n",
      "(Iteration 10 / 100) loss: 1610.532785\n",
      "(Epoch 1 / 10) train acc: 0.136000; val_acc: 0.080000\n",
      "(Iteration 11 / 100) loss: 1608.507939\n",
      "(Iteration 12 / 100) loss: 1609.220797\n",
      "(Iteration 13 / 100) loss: 1603.076399\n",
      "(Iteration 14 / 100) loss: 1607.483467\n",
      "(Iteration 15 / 100) loss: 1603.313500\n",
      "(Iteration 16 / 100) loss: 1602.478531\n",
      "(Iteration 17 / 100) loss: 1600.456871\n",
      "(Iteration 18 / 100) loss: 1596.613998\n",
      "(Iteration 19 / 100) loss: 1597.626140\n",
      "(Iteration 20 / 100) loss: 1595.371498\n",
      "(Epoch 2 / 10) train acc: 0.144000; val_acc: 0.094000\n",
      "(Iteration 21 / 100) loss: 1594.489800\n",
      "(Iteration 22 / 100) loss: 1590.104763\n",
      "(Iteration 23 / 100) loss: 1590.860290\n",
      "(Iteration 24 / 100) loss: 1589.972594\n",
      "(Iteration 25 / 100) loss: 1589.702305\n",
      "(Iteration 26 / 100) loss: 1587.583525\n",
      "(Iteration 27 / 100) loss: 1588.779722\n",
      "(Iteration 28 / 100) loss: 1589.081810\n",
      "(Iteration 29 / 100) loss: 1582.991031\n",
      "(Iteration 30 / 100) loss: 1585.202278\n",
      "(Epoch 3 / 10) train acc: 0.184000; val_acc: 0.112000\n",
      "(Iteration 31 / 100) loss: 1584.047264\n",
      "(Iteration 32 / 100) loss: 1583.035113\n",
      "(Iteration 33 / 100) loss: 1578.887876\n",
      "(Iteration 34 / 100) loss: 1578.546053\n",
      "(Iteration 35 / 100) loss: 1577.242858\n",
      "(Iteration 36 / 100) loss: 1576.974887\n",
      "(Iteration 37 / 100) loss: 1577.427784\n",
      "(Iteration 38 / 100) loss: 1572.194681\n",
      "(Iteration 39 / 100) loss: 1572.443610\n",
      "(Iteration 40 / 100) loss: 1572.496256\n",
      "(Epoch 4 / 10) train acc: 0.224000; val_acc: 0.108000\n",
      "(Iteration 41 / 100) loss: 1568.429210\n",
      "(Iteration 42 / 100) loss: 1568.219265\n",
      "(Iteration 43 / 100) loss: 1566.177330\n",
      "(Iteration 44 / 100) loss: 1565.908019\n",
      "(Iteration 45 / 100) loss: 1564.791316\n",
      "(Iteration 46 / 100) loss: 1564.062852\n",
      "(Iteration 47 / 100) loss: 1562.798364\n",
      "(Iteration 48 / 100) loss: 1561.531008\n",
      "(Iteration 49 / 100) loss: 1560.403778\n",
      "(Iteration 50 / 100) loss: 1559.024584\n",
      "(Epoch 5 / 10) train acc: 0.244000; val_acc: 0.120000\n",
      "(Iteration 51 / 100) loss: 1556.945700\n",
      "(Iteration 52 / 100) loss: 1556.368751\n",
      "(Iteration 53 / 100) loss: 1554.020245\n",
      "(Iteration 54 / 100) loss: 1553.591702\n",
      "(Iteration 55 / 100) loss: 1552.979400\n",
      "(Iteration 56 / 100) loss: 1554.553154\n",
      "(Iteration 57 / 100) loss: 1550.769454\n",
      "(Iteration 58 / 100) loss: 1550.107596\n",
      "(Iteration 59 / 100) loss: 1547.797313\n",
      "(Iteration 60 / 100) loss: 1545.793942\n",
      "(Epoch 6 / 10) train acc: 0.286000; val_acc: 0.116000\n",
      "(Iteration 61 / 100) loss: 1547.280694\n",
      "(Iteration 62 / 100) loss: 1544.744489\n",
      "(Iteration 63 / 100) loss: 1542.150433\n",
      "(Iteration 64 / 100) loss: 1543.756446\n",
      "(Iteration 65 / 100) loss: 1540.369708\n",
      "(Iteration 66 / 100) loss: 1539.034977\n",
      "(Iteration 67 / 100) loss: 1541.235998\n",
      "(Iteration 68 / 100) loss: 1538.893673\n",
      "(Iteration 69 / 100) loss: 1537.755951\n",
      "(Iteration 70 / 100) loss: 1535.655317\n",
      "(Epoch 7 / 10) train acc: 0.366000; val_acc: 0.126000\n",
      "(Iteration 71 / 100) loss: 1535.996450\n",
      "(Iteration 72 / 100) loss: 1532.648503\n",
      "(Iteration 73 / 100) loss: 1529.887056\n",
      "(Iteration 74 / 100) loss: 1530.446631\n",
      "(Iteration 75 / 100) loss: 1532.783115\n",
      "(Iteration 76 / 100) loss: 1530.732395\n",
      "(Iteration 77 / 100) loss: 1531.039953\n",
      "(Iteration 78 / 100) loss: 1529.206499\n",
      "(Iteration 79 / 100) loss: 1526.237049\n",
      "(Iteration 80 / 100) loss: 1523.411939\n",
      "(Epoch 8 / 10) train acc: 0.340000; val_acc: 0.130000\n",
      "(Iteration 81 / 100) loss: 1521.525856\n",
      "(Iteration 82 / 100) loss: 1522.439952\n",
      "(Iteration 83 / 100) loss: 1521.687616\n",
      "(Iteration 84 / 100) loss: 1517.290718\n",
      "(Iteration 85 / 100) loss: 1516.788309\n",
      "(Iteration 86 / 100) loss: 1516.621895\n",
      "(Iteration 87 / 100) loss: 1517.070416\n",
      "(Iteration 88 / 100) loss: 1514.200363\n",
      "(Iteration 89 / 100) loss: 1512.582995\n",
      "(Iteration 90 / 100) loss: 1515.118553\n",
      "(Epoch 9 / 10) train acc: 0.440000; val_acc: 0.138000\n",
      "(Iteration 91 / 100) loss: 1511.582272\n",
      "(Iteration 92 / 100) loss: 1510.541922\n",
      "(Iteration 93 / 100) loss: 1507.002045\n",
      "(Iteration 94 / 100) loss: 1506.775217\n",
      "(Iteration 95 / 100) loss: 1505.741382\n",
      "(Iteration 96 / 100) loss: 1506.680102\n",
      "(Iteration 97 / 100) loss: 1502.811853\n",
      "(Iteration 98 / 100) loss: 1500.996668\n",
      "(Iteration 99 / 100) loss: 1502.703758\n",
      "(Iteration 100 / 100) loss: 1499.165465\n",
      "(Epoch 10 / 10) train acc: 0.484000; val_acc: 0.128000\n",
      "Running weight scale 17 / 20\n",
      "(Iteration 1 / 100) loss: 4263.847220\n",
      "(Epoch 0 / 10) train acc: 0.072000; val_acc: 0.084000\n",
      "(Iteration 2 / 100) loss: 4267.121550\n",
      "(Iteration 3 / 100) loss: 4263.679737\n",
      "(Iteration 4 / 100) loss: 4254.590772\n",
      "(Iteration 5 / 100) loss: 4253.724829\n",
      "(Iteration 6 / 100) loss: 4250.530415\n",
      "(Iteration 7 / 100) loss: 4248.681795\n",
      "(Iteration 8 / 100) loss: 4241.531370\n",
      "(Iteration 9 / 100) loss: 4242.539957\n",
      "(Iteration 10 / 100) loss: 4235.217721\n",
      "(Epoch 1 / 10) train acc: 0.084000; val_acc: 0.092000\n",
      "(Iteration 11 / 100) loss: 4240.606511\n",
      "(Iteration 12 / 100) loss: 4235.330593\n",
      "(Iteration 13 / 100) loss: 4233.907392\n",
      "(Iteration 14 / 100) loss: 4225.084137\n",
      "(Iteration 15 / 100) loss: 4229.188799\n",
      "(Iteration 16 / 100) loss: 4220.174471\n",
      "(Iteration 17 / 100) loss: 4218.099659\n",
      "(Iteration 18 / 100) loss: 4219.962273\n",
      "(Iteration 19 / 100) loss: 4217.684971\n",
      "(Iteration 20 / 100) loss: 4215.165834\n",
      "(Epoch 2 / 10) train acc: 0.088000; val_acc: 0.094000\n",
      "(Iteration 21 / 100) loss: 4218.945898\n",
      "(Iteration 22 / 100) loss: 4209.354637\n",
      "(Iteration 23 / 100) loss: 4207.395633\n",
      "(Iteration 24 / 100) loss: 4206.133679\n",
      "(Iteration 25 / 100) loss: 4209.121814\n",
      "(Iteration 26 / 100) loss: 4204.447724\n",
      "(Iteration 27 / 100) loss: 4201.936397\n",
      "(Iteration 28 / 100) loss: 4194.312658\n",
      "(Iteration 29 / 100) loss: 4194.051352\n",
      "(Iteration 30 / 100) loss: 4197.245808\n",
      "(Epoch 3 / 10) train acc: 0.116000; val_acc: 0.108000\n",
      "(Iteration 31 / 100) loss: 4184.496216\n",
      "(Iteration 32 / 100) loss: 4186.127802\n",
      "(Iteration 33 / 100) loss: 4188.631560\n",
      "(Iteration 34 / 100) loss: 4185.340291\n",
      "(Iteration 35 / 100) loss: 4179.235849\n",
      "(Iteration 36 / 100) loss: 4179.959540\n",
      "(Iteration 37 / 100) loss: 4182.925304\n",
      "(Iteration 38 / 100) loss: 4177.543896\n",
      "(Iteration 39 / 100) loss: 4171.568413\n",
      "(Iteration 40 / 100) loss: 4170.373450\n",
      "(Epoch 4 / 10) train acc: 0.130000; val_acc: 0.122000\n",
      "(Iteration 41 / 100) loss: 4165.556350\n",
      "(Iteration 42 / 100) loss: 4164.683109\n",
      "(Iteration 43 / 100) loss: 4163.722111\n",
      "(Iteration 44 / 100) loss: 4158.998233\n",
      "(Iteration 45 / 100) loss: 4160.208521\n",
      "(Iteration 46 / 100) loss: 4153.848333\n",
      "(Iteration 47 / 100) loss: 4154.172160\n",
      "(Iteration 48 / 100) loss: 4156.088058\n",
      "(Iteration 49 / 100) loss: 4151.215043\n",
      "(Iteration 50 / 100) loss: 4147.752617\n",
      "(Epoch 5 / 10) train acc: 0.152000; val_acc: 0.108000\n",
      "(Iteration 51 / 100) loss: 4142.434446\n",
      "(Iteration 52 / 100) loss: 4142.156737\n",
      "(Iteration 53 / 100) loss: 4142.516094\n",
      "(Iteration 54 / 100) loss: 4137.383675\n",
      "(Iteration 55 / 100) loss: 4136.045238\n",
      "(Iteration 56 / 100) loss: 4131.247480\n",
      "(Iteration 57 / 100) loss: 4129.515644\n",
      "(Iteration 58 / 100) loss: 4127.933076\n",
      "(Iteration 59 / 100) loss: 4128.125237\n",
      "(Iteration 60 / 100) loss: 4127.056366\n",
      "(Epoch 6 / 10) train acc: 0.154000; val_acc: 0.120000\n",
      "(Iteration 61 / 100) loss: 4123.492938\n",
      "(Iteration 62 / 100) loss: 4120.742786\n",
      "(Iteration 63 / 100) loss: 4115.888403\n",
      "(Iteration 64 / 100) loss: 4115.787633\n",
      "(Iteration 65 / 100) loss: 4112.539442\n",
      "(Iteration 66 / 100) loss: 4109.992944\n",
      "(Iteration 67 / 100) loss: 4110.764750\n",
      "(Iteration 68 / 100) loss: 4109.443959\n",
      "(Iteration 69 / 100) loss: 4107.271817\n",
      "(Iteration 70 / 100) loss: 4103.239141\n",
      "(Epoch 7 / 10) train acc: 0.156000; val_acc: 0.118000\n",
      "(Iteration 71 / 100) loss: 4099.768231\n",
      "(Iteration 72 / 100) loss: 4102.006838\n",
      "(Iteration 73 / 100) loss: 4097.091201\n",
      "(Iteration 74 / 100) loss: 4094.639579\n",
      "(Iteration 75 / 100) loss: 4087.735715\n",
      "(Iteration 76 / 100) loss: 4086.998640\n",
      "(Iteration 77 / 100) loss: 4083.648600\n",
      "(Iteration 78 / 100) loss: 4082.204785\n",
      "(Iteration 79 / 100) loss: 4083.483358\n",
      "(Iteration 80 / 100) loss: 4081.897016\n",
      "(Epoch 8 / 10) train acc: 0.222000; val_acc: 0.130000\n",
      "(Iteration 81 / 100) loss: 4082.860044\n",
      "(Iteration 82 / 100) loss: 4080.727214\n",
      "(Iteration 83 / 100) loss: 4075.901590\n",
      "(Iteration 84 / 100) loss: 4072.787478\n",
      "(Iteration 85 / 100) loss: 4066.998869\n",
      "(Iteration 86 / 100) loss: 4067.128900\n",
      "(Iteration 87 / 100) loss: 4068.608470\n",
      "(Iteration 88 / 100) loss: 4064.819380\n",
      "(Iteration 89 / 100) loss: 4065.156002\n",
      "(Iteration 90 / 100) loss: 4062.633741\n",
      "(Epoch 9 / 10) train acc: 0.184000; val_acc: 0.116000\n",
      "(Iteration 91 / 100) loss: 4057.166470\n",
      "(Iteration 92 / 100) loss: 4053.678219\n",
      "(Iteration 93 / 100) loss: 4053.033607\n",
      "(Iteration 94 / 100) loss: 4055.673236\n",
      "(Iteration 95 / 100) loss: 4050.459724\n",
      "(Iteration 96 / 100) loss: 4044.445201\n",
      "(Iteration 97 / 100) loss: 4044.235909\n",
      "(Iteration 98 / 100) loss: 4043.914885\n",
      "(Iteration 99 / 100) loss: 4040.679317\n",
      "(Iteration 100 / 100) loss: 4041.828929\n",
      "(Epoch 10 / 10) train acc: 0.204000; val_acc: 0.120000\n",
      "Running weight scale 18 / 20\n",
      "(Iteration 1 / 100) loss: 11173.434699\n",
      "(Epoch 0 / 10) train acc: 0.096000; val_acc: 0.108000\n",
      "(Iteration 2 / 100) loss: 11168.883558\n",
      "(Iteration 3 / 100) loss: 11165.699143\n",
      "(Iteration 4 / 100) loss: 11150.384181\n",
      "(Iteration 5 / 100) loss: 11141.625567\n",
      "(Iteration 6 / 100) loss: 11160.302368\n",
      "(Iteration 7 / 100) loss: 11141.115081\n",
      "(Iteration 8 / 100) loss: 11135.478071\n",
      "(Iteration 9 / 100) loss: 11136.909058\n",
      "(Iteration 10 / 100) loss: 11128.320861\n",
      "(Epoch 1 / 10) train acc: 0.112000; val_acc: 0.108000\n",
      "(Iteration 11 / 100) loss: 11133.621856\n",
      "(Iteration 12 / 100) loss: 11123.422967\n",
      "(Iteration 13 / 100) loss: 11115.706014\n",
      "(Iteration 14 / 100) loss: 11117.341074\n",
      "(Iteration 15 / 100) loss: 11111.480035\n",
      "(Iteration 16 / 100) loss: 11103.290374\n",
      "(Iteration 17 / 100) loss: 11104.455362\n",
      "(Iteration 18 / 100) loss: 11097.000860\n",
      "(Iteration 19 / 100) loss: 11095.114290\n",
      "(Iteration 20 / 100) loss: 11078.179702\n",
      "(Epoch 2 / 10) train acc: 0.112000; val_acc: 0.088000\n",
      "(Iteration 21 / 100) loss: 11087.837367\n",
      "(Iteration 22 / 100) loss: 11083.306773\n",
      "(Iteration 23 / 100) loss: 11077.802107\n",
      "(Iteration 24 / 100) loss: 11066.697245\n",
      "(Iteration 25 / 100) loss: 11069.077096\n",
      "(Iteration 26 / 100) loss: 11063.893401\n",
      "(Iteration 27 / 100) loss: 11057.738291\n",
      "(Iteration 28 / 100) loss: 11057.640129\n",
      "(Iteration 29 / 100) loss: 11050.690229\n",
      "(Iteration 30 / 100) loss: 11042.563505\n",
      "(Epoch 3 / 10) train acc: 0.128000; val_acc: 0.088000\n",
      "(Iteration 31 / 100) loss: 11034.476500\n",
      "(Iteration 32 / 100) loss: 11034.292291\n",
      "(Iteration 33 / 100) loss: 11028.317601\n",
      "(Iteration 34 / 100) loss: 11036.436609\n",
      "(Iteration 35 / 100) loss: 11027.099857\n",
      "(Iteration 36 / 100) loss: 11021.198342\n",
      "(Iteration 37 / 100) loss: 11027.710958\n",
      "(Iteration 38 / 100) loss: 11014.931457\n",
      "(Iteration 39 / 100) loss: 11013.307964\n",
      "(Iteration 40 / 100) loss: 11002.607385\n",
      "(Epoch 4 / 10) train acc: 0.142000; val_acc: 0.096000\n",
      "(Iteration 41 / 100) loss: 11005.960364\n",
      "(Iteration 42 / 100) loss: 10996.164021\n",
      "(Iteration 43 / 100) loss: 10988.027766\n",
      "(Iteration 44 / 100) loss: 10989.961344\n",
      "(Iteration 45 / 100) loss: 10983.882216\n",
      "(Iteration 46 / 100) loss: 10985.991390\n",
      "(Iteration 47 / 100) loss: 10976.648733\n",
      "(Iteration 48 / 100) loss: 10975.042894\n",
      "(Iteration 49 / 100) loss: 10975.085872\n",
      "(Iteration 50 / 100) loss: 10972.771644\n",
      "(Epoch 5 / 10) train acc: 0.130000; val_acc: 0.102000\n",
      "(Iteration 51 / 100) loss: 10960.730177\n",
      "(Iteration 52 / 100) loss: 10960.313199\n",
      "(Iteration 53 / 100) loss: 10954.217179\n",
      "(Iteration 54 / 100) loss: 10956.571093\n",
      "(Iteration 55 / 100) loss: 10946.767638\n",
      "(Iteration 56 / 100) loss: 10937.329625\n",
      "(Iteration 57 / 100) loss: 10940.109645\n",
      "(Iteration 58 / 100) loss: 10930.236716\n",
      "(Iteration 59 / 100) loss: 10936.499907\n",
      "(Iteration 60 / 100) loss: 10925.360656\n",
      "(Epoch 6 / 10) train acc: 0.132000; val_acc: 0.098000\n",
      "(Iteration 61 / 100) loss: 10926.541538\n",
      "(Iteration 62 / 100) loss: 10919.231116\n",
      "(Iteration 63 / 100) loss: 10914.668919\n",
      "(Iteration 64 / 100) loss: 10911.443255\n",
      "(Iteration 65 / 100) loss: 10911.275188\n",
      "(Iteration 66 / 100) loss: 10900.715413\n",
      "(Iteration 67 / 100) loss: 10900.078581\n",
      "(Iteration 68 / 100) loss: 10894.743820\n",
      "(Iteration 69 / 100) loss: 10894.207081\n",
      "(Iteration 70 / 100) loss: 10885.249553\n",
      "(Epoch 7 / 10) train acc: 0.162000; val_acc: 0.090000\n",
      "(Iteration 71 / 100) loss: 10888.542042\n",
      "(Iteration 72 / 100) loss: 10879.041589\n",
      "(Iteration 73 / 100) loss: 10873.239946\n",
      "(Iteration 74 / 100) loss: 10874.011503\n",
      "(Iteration 75 / 100) loss: 10872.038838\n",
      "(Iteration 76 / 100) loss: 10864.969041\n",
      "(Iteration 77 / 100) loss: 10860.831270\n",
      "(Iteration 78 / 100) loss: 10855.993640\n",
      "(Iteration 79 / 100) loss: 10850.835122\n",
      "(Iteration 80 / 100) loss: 10854.724200\n",
      "(Epoch 8 / 10) train acc: 0.150000; val_acc: 0.104000\n",
      "(Iteration 81 / 100) loss: 10843.873204\n",
      "(Iteration 82 / 100) loss: 10835.729428\n",
      "(Iteration 83 / 100) loss: 10837.070325\n",
      "(Iteration 84 / 100) loss: 10835.167319\n",
      "(Iteration 85 / 100) loss: 10826.149062\n",
      "(Iteration 86 / 100) loss: 10828.183866\n",
      "(Iteration 87 / 100) loss: 10821.417386\n",
      "(Iteration 88 / 100) loss: 10814.258248\n",
      "(Iteration 89 / 100) loss: 10808.774341\n",
      "(Iteration 90 / 100) loss: 10808.033189\n",
      "(Epoch 9 / 10) train acc: 0.168000; val_acc: 0.104000\n",
      "(Iteration 91 / 100) loss: 10801.330299\n",
      "(Iteration 92 / 100) loss: 10804.624268\n",
      "(Iteration 93 / 100) loss: 10799.635923\n",
      "(Iteration 94 / 100) loss: 10795.535249\n",
      "(Iteration 95 / 100) loss: 10785.959412\n",
      "(Iteration 96 / 100) loss: 10783.818301\n",
      "(Iteration 97 / 100) loss: 10782.895155\n",
      "(Iteration 98 / 100) loss: 10781.287292\n",
      "(Iteration 99 / 100) loss: 10777.562726\n",
      "(Iteration 100 / 100) loss: 10768.335721\n",
      "(Epoch 10 / 10) train acc: 0.184000; val_acc: 0.100000\n",
      "Running weight scale 19 / 20\n",
      "(Iteration 1 / 100) loss: 29291.348706\n",
      "(Epoch 0 / 10) train acc: 0.110000; val_acc: 0.116000\n",
      "(Iteration 2 / 100) loss: 29260.258430\n",
      "(Iteration 3 / 100) loss: 29267.938461\n",
      "(Iteration 4 / 100) loss: 29254.307381\n",
      "(Iteration 5 / 100) loss: 29234.850160\n",
      "(Iteration 6 / 100) loss: 29250.718395\n",
      "(Iteration 7 / 100) loss: 29241.517268\n",
      "(Iteration 8 / 100) loss: 29221.792167\n",
      "(Iteration 9 / 100) loss: 29216.398418\n",
      "(Iteration 10 / 100) loss: 29228.890990\n",
      "(Epoch 1 / 10) train acc: 0.124000; val_acc: 0.118000\n",
      "(Iteration 11 / 100) loss: 29206.533240\n",
      "(Iteration 12 / 100) loss: 29194.610097\n",
      "(Iteration 13 / 100) loss: 29183.936994\n",
      "(Iteration 14 / 100) loss: 29171.688532\n",
      "(Iteration 15 / 100) loss: 29182.486575\n",
      "(Iteration 16 / 100) loss: 29177.490744\n",
      "(Iteration 17 / 100) loss: 29169.367580\n",
      "(Iteration 18 / 100) loss: 29158.174622\n",
      "(Iteration 19 / 100) loss: 29157.754243\n",
      "(Iteration 20 / 100) loss: 29142.297629\n",
      "(Epoch 2 / 10) train acc: 0.130000; val_acc: 0.124000\n",
      "(Iteration 21 / 100) loss: 29142.339935\n",
      "(Iteration 22 / 100) loss: 29136.514267\n",
      "(Iteration 23 / 100) loss: 29120.518319\n",
      "(Iteration 24 / 100) loss: 29134.182406\n",
      "(Iteration 25 / 100) loss: 29115.135804\n",
      "(Iteration 26 / 100) loss: 29109.220138\n",
      "(Iteration 27 / 100) loss: 29094.857699\n",
      "(Iteration 28 / 100) loss: 29091.308057\n",
      "(Iteration 29 / 100) loss: 29080.272254\n",
      "(Iteration 30 / 100) loss: 29068.457216\n",
      "(Epoch 3 / 10) train acc: 0.136000; val_acc: 0.122000\n",
      "(Iteration 31 / 100) loss: 29070.656328\n",
      "(Iteration 32 / 100) loss: 29055.880134\n",
      "(Iteration 33 / 100) loss: 29055.276519\n",
      "(Iteration 34 / 100) loss: 29041.443745\n",
      "(Iteration 35 / 100) loss: 29037.442184\n",
      "(Iteration 36 / 100) loss: 29035.599712\n",
      "(Iteration 37 / 100) loss: 29028.606388\n",
      "(Iteration 38 / 100) loss: 29014.037197\n",
      "(Iteration 39 / 100) loss: 29019.071707\n",
      "(Iteration 40 / 100) loss: 29019.874567\n",
      "(Epoch 4 / 10) train acc: 0.150000; val_acc: 0.118000\n",
      "(Iteration 41 / 100) loss: 28991.343640\n",
      "(Iteration 42 / 100) loss: 28988.812729\n",
      "(Iteration 43 / 100) loss: 28980.924753\n",
      "(Iteration 44 / 100) loss: 28968.553523\n",
      "(Iteration 45 / 100) loss: 28968.159910\n",
      "(Iteration 46 / 100) loss: 28973.114386\n",
      "(Iteration 47 / 100) loss: 28951.776861\n",
      "(Iteration 48 / 100) loss: 28937.342631\n",
      "(Iteration 49 / 100) loss: 28936.213058\n",
      "(Iteration 50 / 100) loss: 28948.797718\n",
      "(Epoch 5 / 10) train acc: 0.152000; val_acc: 0.120000\n",
      "(Iteration 51 / 100) loss: 28932.037381\n",
      "(Iteration 52 / 100) loss: 28942.559682\n",
      "(Iteration 53 / 100) loss: 28927.316288\n",
      "(Iteration 54 / 100) loss: 28917.323804\n",
      "(Iteration 55 / 100) loss: 28916.925909\n",
      "(Iteration 56 / 100) loss: 28896.637425\n",
      "(Iteration 57 / 100) loss: 28889.794375\n",
      "(Iteration 58 / 100) loss: 28878.020321\n",
      "(Iteration 59 / 100) loss: 28880.859025\n",
      "(Iteration 60 / 100) loss: 28861.696232\n",
      "(Epoch 6 / 10) train acc: 0.142000; val_acc: 0.112000\n",
      "(Iteration 61 / 100) loss: 28867.127538\n",
      "(Iteration 62 / 100) loss: 28863.822213\n",
      "(Iteration 63 / 100) loss: 28851.419744\n",
      "(Iteration 64 / 100) loss: 28833.895822\n",
      "(Iteration 65 / 100) loss: 28833.347551\n",
      "(Iteration 66 / 100) loss: 28830.693967\n",
      "(Iteration 67 / 100) loss: 28820.121486\n",
      "(Iteration 68 / 100) loss: 28804.914634\n",
      "(Iteration 69 / 100) loss: 28828.554762\n",
      "(Iteration 70 / 100) loss: 28805.465171\n",
      "(Epoch 7 / 10) train acc: 0.168000; val_acc: 0.120000\n",
      "(Iteration 71 / 100) loss: 28786.929301\n",
      "(Iteration 72 / 100) loss: 28787.216559\n",
      "(Iteration 73 / 100) loss: 28785.548363\n",
      "(Iteration 74 / 100) loss: 28764.757747\n",
      "(Iteration 75 / 100) loss: 28779.511355\n",
      "(Iteration 76 / 100) loss: 28761.887345\n",
      "(Iteration 77 / 100) loss: 28748.641736\n",
      "(Iteration 78 / 100) loss: 28754.427512\n",
      "(Iteration 79 / 100) loss: 28740.269106\n",
      "(Iteration 80 / 100) loss: 28735.142082\n",
      "(Epoch 8 / 10) train acc: 0.176000; val_acc: 0.122000\n",
      "(Iteration 81 / 100) loss: 28725.037132\n",
      "(Iteration 82 / 100) loss: 28719.957258\n",
      "(Iteration 83 / 100) loss: 28716.438253\n",
      "(Iteration 84 / 100) loss: 28710.228647\n",
      "(Iteration 85 / 100) loss: 28691.804148\n",
      "(Iteration 86 / 100) loss: 28690.444447\n",
      "(Iteration 87 / 100) loss: 28683.172741\n",
      "(Iteration 88 / 100) loss: 28669.915672\n",
      "(Iteration 89 / 100) loss: 28662.224664\n",
      "(Iteration 90 / 100) loss: 28656.801320\n",
      "(Epoch 9 / 10) train acc: 0.170000; val_acc: 0.126000\n",
      "(Iteration 91 / 100) loss: 28664.796314\n",
      "(Iteration 92 / 100) loss: 28651.761105\n",
      "(Iteration 93 / 100) loss: 28659.785603\n",
      "(Iteration 94 / 100) loss: 28636.104350\n",
      "(Iteration 95 / 100) loss: 28634.475973\n",
      "(Iteration 96 / 100) loss: 28635.766847\n",
      "(Iteration 97 / 100) loss: 28616.129341\n",
      "(Iteration 98 / 100) loss: 28607.541889\n",
      "(Iteration 99 / 100) loss: 28597.250694\n",
      "(Iteration 100 / 100) loss: 28599.268480\n",
      "(Epoch 10 / 10) train acc: 0.158000; val_acc: 0.126000\n",
      "Running weight scale 20 / 20\n",
      "(Iteration 1 / 100) loss: 77304.100550\n",
      "(Epoch 0 / 10) train acc: 0.110000; val_acc: 0.112000\n",
      "(Iteration 2 / 100) loss: 77267.618570\n",
      "(Iteration 3 / 100) loss: 77309.668743\n",
      "(Iteration 4 / 100) loss: 77298.863951\n",
      "(Iteration 5 / 100) loss: 77284.215346\n",
      "(Iteration 6 / 100) loss: 77244.099540\n",
      "(Iteration 7 / 100) loss: 77239.832836\n",
      "(Iteration 8 / 100) loss: 77230.125419\n",
      "(Iteration 9 / 100) loss: 77207.399386\n",
      "(Iteration 10 / 100) loss: 77218.665147\n",
      "(Epoch 1 / 10) train acc: 0.142000; val_acc: 0.100000\n",
      "(Iteration 11 / 100) loss: 77181.700446\n",
      "(Iteration 12 / 100) loss: 77156.579979\n",
      "(Iteration 13 / 100) loss: 77172.488575\n",
      "(Iteration 14 / 100) loss: 77146.118957\n",
      "(Iteration 15 / 100) loss: 77164.195977\n",
      "(Iteration 16 / 100) loss: 77163.265797\n",
      "(Iteration 17 / 100) loss: 77101.804345\n",
      "(Iteration 18 / 100) loss: 77107.943820\n",
      "(Iteration 19 / 100) loss: 77079.128653\n",
      "(Iteration 20 / 100) loss: 77092.802090\n",
      "(Epoch 2 / 10) train acc: 0.128000; val_acc: 0.102000\n",
      "(Iteration 21 / 100) loss: 77060.723573\n",
      "(Iteration 22 / 100) loss: 77075.929745\n",
      "(Iteration 23 / 100) loss: 77023.517687\n",
      "(Iteration 24 / 100) loss: 77025.652939\n",
      "(Iteration 25 / 100) loss: 77045.676787\n",
      "(Iteration 26 / 100) loss: 77024.889211\n",
      "(Iteration 27 / 100) loss: 77015.263360\n",
      "(Iteration 28 / 100) loss: 77001.527677\n",
      "(Iteration 29 / 100) loss: 76977.839577\n",
      "(Iteration 30 / 100) loss: 76975.456943\n",
      "(Epoch 3 / 10) train acc: 0.112000; val_acc: 0.094000\n",
      "(Iteration 31 / 100) loss: 76978.237006\n",
      "(Iteration 32 / 100) loss: 76957.546876\n",
      "(Iteration 33 / 100) loss: 76930.053151\n",
      "(Iteration 34 / 100) loss: 76895.674136\n",
      "(Iteration 35 / 100) loss: 76927.119869\n",
      "(Iteration 36 / 100) loss: 76890.893409\n",
      "(Iteration 37 / 100) loss: 76888.555203\n",
      "(Iteration 38 / 100) loss: 76903.541463\n",
      "(Iteration 39 / 100) loss: 76872.995896\n",
      "(Iteration 40 / 100) loss: 76856.207084\n",
      "(Epoch 4 / 10) train acc: 0.140000; val_acc: 0.118000\n",
      "(Iteration 41 / 100) loss: 76849.916859\n",
      "(Iteration 42 / 100) loss: 76839.332158\n",
      "(Iteration 43 / 100) loss: 76844.531482\n",
      "(Iteration 44 / 100) loss: 76814.530951\n",
      "(Iteration 45 / 100) loss: 76799.470769\n",
      "(Iteration 46 / 100) loss: 76801.787703\n",
      "(Iteration 47 / 100) loss: 76746.571513\n",
      "(Iteration 48 / 100) loss: 76726.791843\n",
      "(Iteration 49 / 100) loss: 76774.506540\n",
      "(Iteration 50 / 100) loss: 76701.093027\n",
      "(Epoch 5 / 10) train acc: 0.132000; val_acc: 0.096000\n",
      "(Iteration 51 / 100) loss: 76715.108151\n",
      "(Iteration 52 / 100) loss: 76726.999525\n",
      "(Iteration 53 / 100) loss: 76682.732082\n",
      "(Iteration 54 / 100) loss: 76694.158122\n",
      "(Iteration 55 / 100) loss: 76680.149240\n",
      "(Iteration 56 / 100) loss: 76668.908743\n",
      "(Iteration 57 / 100) loss: 76666.995248\n",
      "(Iteration 58 / 100) loss: 76621.087805\n",
      "(Iteration 59 / 100) loss: 76608.623285\n",
      "(Iteration 60 / 100) loss: 76612.097738\n",
      "(Epoch 6 / 10) train acc: 0.124000; val_acc: 0.108000\n",
      "(Iteration 61 / 100) loss: 76608.760083\n",
      "(Iteration 62 / 100) loss: 76587.625856\n",
      "(Iteration 63 / 100) loss: 76591.702421\n",
      "(Iteration 64 / 100) loss: 76549.894130\n",
      "(Iteration 65 / 100) loss: 76575.251863\n",
      "(Iteration 66 / 100) loss: 76525.909439\n",
      "(Iteration 67 / 100) loss: 76504.807699\n",
      "(Iteration 68 / 100) loss: 76512.244933\n",
      "(Iteration 69 / 100) loss: 76500.436660\n",
      "(Iteration 70 / 100) loss: 76494.502026\n",
      "(Epoch 7 / 10) train acc: 0.124000; val_acc: 0.108000\n",
      "(Iteration 71 / 100) loss: 76509.495989\n",
      "(Iteration 72 / 100) loss: 76472.923681\n",
      "(Iteration 73 / 100) loss: 76444.375743\n",
      "(Iteration 74 / 100) loss: 76448.148527\n",
      "(Iteration 75 / 100) loss: 76451.766790\n",
      "(Iteration 76 / 100) loss: 76446.862721\n",
      "(Iteration 77 / 100) loss: 76417.097841\n",
      "(Iteration 78 / 100) loss: 76429.458918\n",
      "(Iteration 79 / 100) loss: 76381.840949\n",
      "(Iteration 80 / 100) loss: 76371.536371\n",
      "(Epoch 8 / 10) train acc: 0.126000; val_acc: 0.092000\n",
      "(Iteration 81 / 100) loss: 76369.294608\n",
      "(Iteration 82 / 100) loss: 76344.984791\n",
      "(Iteration 83 / 100) loss: 76358.922215\n",
      "(Iteration 84 / 100) loss: 76339.992861\n",
      "(Iteration 85 / 100) loss: 76325.948673\n",
      "(Iteration 86 / 100) loss: 76321.445064\n",
      "(Iteration 87 / 100) loss: 76292.669875\n",
      "(Iteration 88 / 100) loss: 76299.774415\n",
      "(Iteration 89 / 100) loss: 76285.588294\n",
      "(Iteration 90 / 100) loss: 76272.234455\n",
      "(Epoch 9 / 10) train acc: 0.120000; val_acc: 0.098000\n",
      "(Iteration 91 / 100) loss: 76271.360414\n",
      "(Iteration 92 / 100) loss: 76267.619905\n",
      "(Iteration 93 / 100) loss: 76215.336304\n",
      "(Iteration 94 / 100) loss: 76203.463931\n",
      "(Iteration 95 / 100) loss: 76225.566886\n",
      "(Iteration 96 / 100) loss: 76209.827299\n",
      "(Iteration 97 / 100) loss: 76183.637057\n",
      "(Iteration 98 / 100) loss: 76214.500667\n",
      "(Iteration 99 / 100) loss: 76168.336170\n",
      "(Iteration 100 / 100) loss: 76137.209217\n",
      "(Epoch 10 / 10) train acc: 0.136000; val_acc: 0.098000\n"
     ]
    }
   ],
   "source": [
    "from classifiers import cnn_huge as cnn\n",
    "bn_solvers = {}\n",
    "solvers = {}\n",
    "weight_scales = np.logspace(-4, 0, num=20)\n",
    "for i, weight_scale in enumerate(weight_scales):\n",
    "  print 'Running weight scale %d / %d' % (i + 1, len(weight_scales))\n",
    "  bn_model = cnn.ResNet(reg=0.5, weight_scale=weight_scale, use_batchnorm=True)\n",
    "  #model = FullyConnectedNet(hidden_dims, weight_scale=weight_scale, use_batchnorm=False)\n",
    "\n",
    "  bn_solver = Solver(bn_model, small_data,\n",
    "                  num_epochs=10, batch_size=50,\n",
    "                  update_rule='adam',\n",
    "                  optim_config={\n",
    "                    'learning_rate': 1e-4,\n",
    "                  },\n",
    "                  verbose=True, print_every=1)\n",
    "  bn_solver.train()\n",
    "  bn_solvers[weight_scale] = bn_solver\n",
    "\n",
    "  #solver = Solver(model, small_data,\n",
    "  #                num_epochs=10, batch_size=50,\n",
    "  #                update_rule='adam',\n",
    "  #                optim_config={\n",
    "  #                  'learning_rate': 1e-3,\n",
    "  #                },\n",
    "  #                verbose=False, print_every=200)\n",
    "  #solver.train()\n",
    "  #solvers[weight_scale] = solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "best_train_accs, bn_best_train_accs = [], []\n",
    "best_val_accs, bn_best_val_accs = [], []\n",
    "final_train_loss, bn_final_train_loss = [], []\n",
    "i = 0\n",
    "print len(bn_solvers)\n",
    "for ws in weight_scales:\n",
    "  i += 1\n",
    "  if i < 21:\n",
    "      pass\n",
    "      #best_train_accs.append(max(solvers[ws].train_acc_history))\n",
    "      bn_best_train_accs.append(max(bn_solvers[ws].train_acc_history))\n",
    "  \n",
    "      #best_val_accs.append(max(solvers[ws].val_acc_history))\n",
    "      bn_best_val_accs.append(max(bn_solvers[ws].val_acc_history))\n",
    "  \n",
    "      #final_train_loss.append(np.mean(solvers[ws].loss_history[-100:]))\n",
    "      bn_final_train_loss.append(np.mean(bn_solvers[ws].loss_history[-100:]))\n",
    "\n",
    "print len(bn_best_train_accs)   \n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Best val accuracy vs weight initialization scale')\n",
    "plt.xlabel('Weight initialization scale')\n",
    "plt.ylabel('Best val accuracy')\n",
    "#plt.semilogx(weight_scales, best_val_accs, '-o', label='baseline')\n",
    "plt.semilogx(weight_scales[:20], bn_best_val_accs, '-o', label='batchnorm')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Best train accuracy vs weight initialization scale')\n",
    "plt.xlabel('Weight initialization scale')\n",
    "plt.ylabel('Best training accuracy')\n",
    "#plt.semilogx(weight_scales, best_train_accs, '-o', label='baseline')\n",
    "plt.semilogx(weight_scales[:20], bn_best_train_accs, '-o', label='batchnorm')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Final training loss vs weight initialization scale')\n",
    "plt.xlabel('Weight initialization scale')\n",
    "plt.ylabel('Final training loss')\n",
    "#plt.semilogx(weight_scales, final_train_loss, '-o', label='baseline')\n",
    "plt.semilogx(weight_scales[:20], bn_final_train_loss, '-o', label='batchnorm')\n",
    "plt.legend()\n",
    "\n",
    "plt.gcf().set_size_inches(10, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-04   1.62377674e-04   2.63665090e-04   4.28133240e-04\n",
      "   6.95192796e-04   1.12883789e-03   1.83298071e-03   2.97635144e-03\n",
      "   4.83293024e-03   7.84759970e-03   1.27427499e-02   2.06913808e-02\n",
      "   3.35981829e-02   5.45559478e-02   8.85866790e-02   1.43844989e-01\n",
      "   2.33572147e-01   3.79269019e-01   6.15848211e-01   1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print weight_scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
