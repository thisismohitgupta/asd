{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (1000, 3, 32, 32)\n",
      "X_train:  (49000, 3, 32, 32)\n",
      "X_test:  (1000, 3, 32, 32)\n",
      "y_val:  (1000,)\n",
      "y_train:  (49000,)\n",
      "y_test:  (1000,)\n",
      "dx error:  -1674109.24936\n"
     ]
    }
   ],
   "source": [
    "from Layers import Layers\n",
    "from checks import Checks\n",
    "from data_utils.data import get_CIFAR10_data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape\n",
    "from classifiers.cnn import ThreeLayerConvNet\n",
    "num_train = 4\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "\n",
    "x = data['X_train'][:1]\n",
    "w = np.random.randn(3, 3, 3, 3)\n",
    "w2 = np.random.randn(3, 3, 3, 3)\n",
    "b = np.random.randn(3,)\n",
    "b2 = np.random.randn(3,)\n",
    "gamma1 = np.ones(3)\n",
    "gamma2 = np.ones(3)\n",
    "beta1 = np.zeros(3)\n",
    "beta2 = np.zeros(3)\n",
    "bn_params_1 = {}\n",
    "bn_params_2 = {}\n",
    "bn_params_1['mode'] = 'train'\n",
    "bn_params_2['mode'] = 'train'\n",
    "CW = 0\n",
    "Cb = 0\n",
    "conv_param1 = {'stride': 1, 'pad': 1}\n",
    "conv_param2 = {'stride': 1, 'pad': 1}\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ly = Layers()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resNet_out_,conv_layer_cache,relu_cache_,conv_layer_cache_2,relu_cache_2,x_pad_,bachnorm_layer_cache,bachnorm_layer_cache2 = ly.resNetUnit_forward2(x,w,b,w2,b2,gamma1,beta1,gamma2,beta2 ,bn_params_1 , bn_params_2, CW,Cb,conv_param1,conv_param2)\n",
    "\n",
    "a = ly.resNetUnit_backward2(resNet_out_,conv_layer_cache, relu_cache_, conv_layer_cache_2, relu_cache_2,bachnorm_layer_cache,bachnorm_layer_cache2,x_pad_)\n",
    "\n",
    "#\n",
    "ck = Checks()\n",
    "dx_num = ck.eval_numerical_gradient_array( x,lambda x: ly.resNetUnit_forward2(x,w,b,w2,b2,gamma1,beta1,gamma2,beta2 ,bn_params_1 , bn_params_2, CW,Cb,conv_param1,conv_param2)[0], a[0])\n",
    "\n",
    "print 'dx error: ', np.sum(dx_num - a[0])\n",
    "# dw_num = ck.eval_numerical_gradient_array(lambda w: ly.conv_relu_forward(x, w, b, conv_param)[0], w, dout)\n",
    "# db_num = ck.eval_numerical_gradient_array(lambda b: ly.conv_relu_forward(x, w, b, conv_param)[0], b, dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,3,32,32) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-cc13c718401f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_numerical_gradient_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconv_forward_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_param1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thisismohit/Dropbox/ConvolutionalNN/checks.pyc\u001b[0m in \u001b[0;36meval_numerical_gradient_array\u001b[1;34m(self, x, f, df, h)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moldval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mneg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miternext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,3,32,32) (3,) "
     ]
    }
   ],
   "source": [
    "from faster.fast_layers import conv_forward_fast,conv_backward_fast\n",
    "\n",
    "conv_layer_1 , conv_layer1_cache = conv_forward_fast(x, w, b, conv_param1)\n",
    "\n",
    "dx, dw1, db1 = conv_backward_fast(conv_layer_1,conv_layer1_cache)\n",
    "X = x\n",
    "x = w\n",
    "dm = ck.eval_numerical_gradient_array(b,lambda x: conv_forward_fast(X, w, x, conv_param1)[0],db1)\n",
    "\n",
    "\n",
    "print 'dx error: ', np.sum(np.subtract(dm, db1))\n",
    "\n",
    "# conv_out,cache1, rcache, cache2, rcahce2, x_pad = ly.resNetUnit_forward(out,w,b,w2,b2,conv_param)\n",
    "#\n",
    "# print conv_out.shape\n",
    "#\n",
    "# dx,dw1 = ly.resNetUnit_backward(conv_out,cache1, rcache, cache2, rcahce2)\n",
    "#\n",
    "# print dx.shape\n",
    "#\n",
    "# import checks as cks\n",
    "#\n",
    "# hello = cks.Checks()\n",
    "#\n",
    "# grad = hello.eval_numerical_gradient_array( out,lambda X: ly.resNetUnit_forward(X,w,b,w2,b2,conv_param)[0], dx)\n",
    "#\n",
    "#\n",
    "# #print grad[1].shape\n",
    "# #print np.subtract(grad, dw1)\n",
    "# print np.sum(np.subtract(grad, dx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print 'Testing conv_relu:'\n",
    "# print 'dx error: ', np.subtract(dx_num, dx)\n",
    "# print 'dw error: ', np.subtract(dw_num, dw)\n",
    "# print 'db error: ', np.subtract(db_num, db)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
